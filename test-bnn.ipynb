{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f993ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch + Pyro BNN with NUTS MCMC for sinusoidal toy regression\n",
    "# Heteroscedastic likelihood: y ~ Normal(mu(x), sigma(x)), sigma(x) via Softplus\n",
    "# Decomposition: aleatoric = E[sigma^2], epistemic = Var(mu) across posterior samples\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import MCMC, NUTS, Predictive\n",
    "\n",
    "pyro.set_rng_seed(0)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ---------- Data (paper setup) ----------\n",
    "def generate_toy_regression(n_train=1000, train_range=(0.0, 10.0), ood_range=(10.0, 15.0), grid_points=600, seed=0):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    low, high = train_range\n",
    "    x_train = rng.uniform(low, high, size=(n_train, 1))\n",
    "    eps1 = rng.normal(0.0, 0.3, size=(n_train, 1))\n",
    "    eps2 = rng.normal(0.0, 0.3, size=(n_train, 1))\n",
    "    y_train = x_train * np.sin(x_train) + eps1 * x_train + eps2\n",
    "\n",
    "    x_grid = np.linspace(train_range[0], ood_range[1], grid_points).reshape(-1, 1)\n",
    "    y_clean = x_grid * np.sin(x_grid)\n",
    "    ood_mask = (x_grid[:, 0] > train_range[1])\n",
    "\n",
    "    return (x_train.astype(np.float32), y_train.astype(np.float32),\n",
    "            x_grid.astype(np.float32), y_clean.astype(np.float32), ood_mask)\n",
    "\n",
    "# ---------- Model ----------\n",
    "def forward_nn(x, W1, b1, W2, b2, W_mu, b_mu, W_rho, b_rho):\n",
    "    # x: [N,1]; all params are tensors\n",
    "    h1 = F.relu(x @ W1 + b1)           # [N,H]\n",
    "    h2 = F.relu(h1 @ W2 + b2)          # [N,H]\n",
    "    mu = h2 @ W_mu + b_mu              # [N,1]\n",
    "    rho = h2 @ W_rho + b_rho           # [N,1]\n",
    "    sigma = F.softplus(rho) + 1e-6     # [N,1], positive std\n",
    "    return mu.squeeze(-1), sigma.squeeze(-1)\n",
    "\n",
    "def bnn_model(x, y=None, hidden_width=16, weight_scale=1.0):\n",
    "    N = x.shape[0]\n",
    "    H = hidden_width\n",
    "\n",
    "    # Priors on weights/biases (Gaussian)\n",
    "    W1   = pyro.sample(\"W1\",   dist.Normal(0, weight_scale).expand([1, H]).to_event(2))\n",
    "    b1   = pyro.sample(\"b1\",   dist.Normal(0, weight_scale).expand([H]).to_event(1))\n",
    "    W2   = pyro.sample(\"W2\",   dist.Normal(0, weight_scale).expand([H, H]).to_event(2))\n",
    "    b2   = pyro.sample(\"b2\",   dist.Normal(0, weight_scale).expand([H]).to_event(1))\n",
    "    W_mu = pyro.sample(\"W_mu\", dist.Normal(0, weight_scale).expand([H, 1]).to_event(2))\n",
    "    b_mu = pyro.sample(\"b_mu\", dist.Normal(0, weight_scale).expand([1]).to_event(1))\n",
    "    W_rho= pyro.sample(\"W_rho\",dist.Normal(0, weight_scale).expand([H, 1]).to_event(2))\n",
    "    b_rho= pyro.sample(\"b_rho\",dist.Normal(0, weight_scale).expand([1]).to_event(1))\n",
    "\n",
    "    mu, sigma = forward_nn(x, W1, b1, W2, b2, W_mu, b_mu, W_rho, b_rho)  # [N], [N]\n",
    "    pyro.deterministic(\"mu\",   mu)\n",
    "    pyro.deterministic(\"sigma\",sigma)\n",
    "\n",
    "    with pyro.plate(\"data\", N):\n",
    "        pyro.sample(\"obs\", dist.Normal(mu, sigma), obs=y if y is not None else None)\n",
    "\n",
    "# ---------- MCMC ----------\n",
    "def run_nuts(x_train_t, y_train_t, hidden_width=16, weight_scale=1.0,\n",
    "             warmup=800, samples=800, chains=1):\n",
    "    nuts_kernel = NUTS(bnn_model, target_accept_prob=0.8)\n",
    "    # older Pyro API uses warmup_steps\n",
    "    mcmc = MCMC(nuts_kernel, num_samples=samples, warmup_steps=warmup, num_chains=chains)\n",
    "    mcmc.run(x=x_train_t, y=y_train_t, hidden_width=hidden_width, weight_scale=weight_scale)\n",
    "    return mcmc\n",
    "\n",
    "def posterior_predictive(mcmc, x_new_t, hidden_width=16, weight_scale=1.0):\n",
    "    samples = mcmc.get_samples()\n",
    "    predictive = Predictive(bnn_model, posterior_samples=samples, return_sites=(\"mu\",\"sigma\",\"obs\"))\n",
    "    preds = predictive(x=x_new_t, hidden_width=hidden_width, weight_scale=weight_scale)\n",
    "    return {k: v.detach().cpu().numpy() for k, v in preds.items()}\n",
    "\n",
    "# ---------- Decomposition ----------\n",
    "def decompose_uncertainty(mu_samples, sigma_samples):\n",
    "    # Handle potential extra dimensions from Pyro\n",
    "    if mu_samples.ndim > 2:\n",
    "        mu_samples = mu_samples.squeeze()\n",
    "    if sigma_samples.ndim > 2:\n",
    "        sigma_samples = sigma_samples.squeeze()\n",
    "    \n",
    "    # Ensure we have [S,N] shape\n",
    "    if mu_samples.ndim == 1:\n",
    "        mu_samples = mu_samples.reshape(1, -1)\n",
    "    if sigma_samples.ndim == 1:\n",
    "        sigma_samples = sigma_samples.reshape(1, -1)\n",
    "    \n",
    "    # mu_samples: [S,N], sigma_samples: [S,N]\n",
    "    aleatoric_var = (sigma_samples**2).mean(axis=0)   # E[σ²]\n",
    "    epistemic_var = mu_samples.var(axis=0)            # Var[μ]\n",
    "    total_var = aleatoric_var + epistemic_var\n",
    "    mu_mean = mu_samples.mean(axis=0)\n",
    "    return mu_mean, aleatoric_var, epistemic_var, total_var\n",
    "\n",
    "# ---------- Plot ----------\n",
    "def plot_uncertainties(x_grid, y_clean, mu_pred, ale_var, epi_var, tot_var, title=\"BNN (Pyro NUTS)\"):\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(8, 10), sharex=True)\n",
    "    x = x_grid[:, 0]\n",
    "\n",
    "    axes[0].plot(x, mu_pred, label=\"Predictive mean\")\n",
    "    axes[0].fill_between(x, mu_pred - np.sqrt(tot_var), mu_pred + np.sqrt(tot_var), alpha=0.2, label=\"±1σ total\")\n",
    "    axes[0].plot(x, y_clean[:, 0], linestyle='--', alpha=0.6, label=\"Clean f(x) = x sin(x)\")\n",
    "    axes[0].set_ylabel(\"y\"); axes[0].set_title(title); axes[0].legend(loc=\"upper left\")\n",
    "\n",
    "    axes[1].plot(x, np.sqrt(ale_var)); axes[1].set_ylabel(\"Aleatoric σ\")\n",
    "    axes[2].plot(x, np.sqrt(epi_var)); axes[2].set_ylabel(\"Epistemic σ\"); axes[2].set_xlabel(\"x\")\n",
    "\n",
    "    for ax in axes:\n",
    "        ax.axvspan(x.min(), 10.0, alpha=0.05, color='gray')\n",
    "        ax.axvspan(10.0, x.max(), alpha=0.10, color='lightgray')\n",
    "\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "# ---------- Main ----------\n",
    "def main():\n",
    "    x_train, y_train, x_grid, y_clean, _ = generate_toy_regression(n_train=1000, seed=0)\n",
    "\n",
    "    x_train_t = torch.from_numpy(x_train).to(device)\n",
    "    y_train_t = torch.from_numpy(y_train.squeeze(-1)).to(device)\n",
    "    x_grid_t  = torch.from_numpy(x_grid).to(device)\n",
    "\n",
    "    hidden_width = 16     # increase to 32 if you have more compute\n",
    "    weight_scale = 1.0\n",
    "    warmup = 800\n",
    "    samples = 800\n",
    "    chains = 1\n",
    "\n",
    "    mcmc = run_nuts(x_train_t, y_train_t, hidden_width, weight_scale, warmup, samples, chains)\n",
    "    preds = posterior_predictive(mcmc, x_grid_t, hidden_width, weight_scale)\n",
    "    mu_samps = preds[\"mu\"]       # [S,N]\n",
    "    sigma_samps = preds[\"sigma\"] # [S,N]\n",
    "    \n",
    "    # Debug: print shapes\n",
    "    print(f\"mu_samps shape: {mu_samps.shape}\")\n",
    "    print(f\"sigma_samps shape: {sigma_samps.shape}\")\n",
    "\n",
    "    mu_pred, ale_var, epi_var, tot_var = decompose_uncertainty(mu_samps, sigma_samps)\n",
    "    \n",
    "    # Debug: print final shapes\n",
    "    print(f\"mu_pred shape: {mu_pred.shape}\")\n",
    "    print(f\"ale_var shape: {ale_var.shape}\")\n",
    "    print(f\"epi_var shape: {epi_var.shape}\")\n",
    "    print(f\"tot_var shape: {tot_var.shape}\")\n",
    "    plot_uncertainties(x_grid, y_clean, mu_pred, ale_var, epi_var, tot_var, title=\"BNN (Pyro NUTS) — Heteroscedastic\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
