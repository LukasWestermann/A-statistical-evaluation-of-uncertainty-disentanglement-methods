{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7028593f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error importing in API mode: ImportError('On Windows, cffi mode \"ANY\" is only \"ABI\".')\n",
      "Trying to import in ABI mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results will be saved to: c:\\Users\\lukas\\OneDrive\\Desktop\\Code-Masterarbeit\\A-statistical-evaluation-of-uncertainty-disentanglement-methods-1\\results\\noise_level\n",
      "CUDA not available. Using CPU.\n",
      "CUDA not available. Using CPU.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from typing import Tuple\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import os\n",
    "import pyro\n",
    "\n",
    "# Add parent directory to path to import Models\n",
    "# This works for notebooks in the Experiments folder\n",
    "project_root = Path.cwd().parent if Path.cwd().name == 'Experiments' else Path.cwd()\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Setup results directory\n",
    "results_dir = project_root / \"results\" / \"noise_level\"\n",
    "results_dir.mkdir(parents=True, exist_ok=True)\n",
    "plots_dir = results_dir / \"plots\"\n",
    "plots_dir.mkdir(exist_ok=True)\n",
    "stats_dir = results_dir / \"statistics\"\n",
    "stats_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"Results will be saved to: {results_dir}\")\n",
    "\n",
    "# Import from Models folder\n",
    "from Models.MC_Dropout import (\n",
    "    MCDropoutRegressor,\n",
    "    train_model,\n",
    "    mc_dropout_predict,\n",
    "    gaussian_nll,\n",
    "    beta_nll,\n",
    "    plot_toy_data,\n",
    "    plot_uncertainties,\n",
    "    normalize_x,\n",
    "    normalize_x_data\n",
    ")\n",
    "\n",
    "from Models.Deep_Ensemble import (\n",
    "    train_ensemble_deep,\n",
    "    ensemble_predict_deep\n",
    ")\n",
    "\n",
    "from Models.BNN import (\n",
    "    train_bnn,\n",
    "    bnn_predict,\n",
    "    normalize_x as bnn_normalize_x,\n",
    "    normalize_x_data as bnn_normalize_x_data\n",
    ")\n",
    "\n",
    "from Models.BAMLSS import (\n",
    "    fit_bamlss,\n",
    "    bamlss_predict\n",
    ")\n",
    "\n",
    "from utils.device import get_device\n",
    "from utils.plotting import plot_toy_data, plot_uncertainties_no_ood\n",
    "import utils.results_save as results_save_module\n",
    "from utils.results_save import save_plot, save_statistics, save_summary_text, save_summary_statistics\n",
    "\n",
    "# Import helper functions for sample size experiments\n",
    "from utils.sample_size_experiments import (\n",
    "    run_mc_dropout_sample_size_experiment,\n",
    "    run_deep_ensemble_sample_size_experiment,\n",
    "    run_bnn_sample_size_experiment,\n",
    "    run_bamlss_sample_size_experiment\n",
    ")\n",
    "\n",
    "# Import helper functions for noise level experiments\n",
    "from utils.noise_level_experiments import (\n",
    "    run_mc_dropout_noise_level_experiment,\n",
    "    run_deep_ensemble_noise_level_experiment,\n",
    "    run_bnn_noise_level_experiment,\n",
    "    run_bamlss_noise_level_experiment\n",
    ")\n",
    "\n",
    "# Set the module-level directories for results_save\n",
    "results_save_module.plots_dir = plots_dir\n",
    "results_save_module.stats_dir = stats_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "840dc934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducibility\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# ----- Data generation for linear function with homo/heteroscedastic noise -----\n",
    "# f(x) = 0.7x + 0.5\n",
    "# noise_type: 'homoscedastic' (σ(x) = 0.20) or 'heteroscedastic' (σ(x) = 0.10 + 0.2(0.5 + 0.5sin(x)))\n",
    "def generate_toy_regression(n_train=1000, train_range=(0.0, 10.0), \n",
    "                           grid_points=1000, noise_type='heteroscedastic', type = \"linear\", tau = 1 , distribution = \"normal\"):\n",
    "    low, high = train_range\n",
    "    x_train = np.random.uniform(low, high, size=(n_train, 1))\n",
    "    \n",
    "    if type == \"linear\":\n",
    "        # Linear function: f(x) = 0.7x + 0.5\n",
    "        f_clean = lambda x: 0.7 * x + 0.5\n",
    "        y_clean_train = f_clean(x_train)\n",
    "    elif type == \"sin\":\n",
    "        f_clean = lambda x:  x * np.sin(x) + x\n",
    "        y_clean_train = f_clean(x_train)\n",
    "    else:\n",
    "        raise ValueError(\"type must be 'linear', 'sin'\")\n",
    "\n",
    "    # Define noise variance σ²(x)\n",
    "    if noise_type == 'homoscedastic':\n",
    "        # Homoscedastic: σ(x) = tau\n",
    "        sigma = tau\n",
    "        sigma_train = np.full_like(x_train, sigma)\n",
    "    elif noise_type == 'heteroscedastic':\n",
    "        # Heteroscedastic: \n",
    "        sigma_train = np.abs(tau * np.sin(0.5*x_train +5))\n",
    "    else:\n",
    "        raise ValueError(\"noise_type must be 'homoscedastic' or 'heteroscedastic'\")\n",
    "    \n",
    "    # Generate noise: ε | x ~ N(0, σ²(x))\n",
    "    if distribution == \"normal\":\n",
    "        epsilon = np.random.normal(0.0, sigma_train, size=(n_train, 1))\n",
    "    elif distribution == \"laplace\":\n",
    "        epsilon = np.random.laplace(0.0, sigma_train, size=(n_train, 1))\n",
    "    else:\n",
    "        raise ValueError(\"distribution must be 'normal' or 'laplace'\")\n",
    "    y_train = y_clean_train + epsilon\n",
    "\n",
    "    # Dense evaluation grid within training range\n",
    "    x_grid = np.linspace(train_range[0], train_range[1], grid_points).reshape(-1, 1)\n",
    "    y_grid_clean = f_clean(x_grid)\n",
    "\n",
    "    return (x_train.astype(np.float32), y_train.astype(np.float32),\n",
    "            x_grid.astype(np.float32), y_grid_clean.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ad8e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_values = [0.5, 1, 2, 2.5, 5, 10]\n",
    "\n",
    "for tau in tau_values:\n",
    "    # Polynomial function with homoscedastic noise\n",
    "    x_train_homo, y_train_homo, x_grid_homo, y_clean_homo = generate_toy_regression(\n",
    "        n_train=1000, \n",
    "        train_range=(-5,10), \n",
    "        noise_type='homoscedastic',\n",
    "        type = \"sin\",\n",
    "        tau = tau,\n",
    "        distribution = \"laplace\"\n",
    "    )\n",
    "\n",
    "    plot_toy_data(x_train_homo, y_train_homo, x_grid_homo, y_clean_homo, title=\"Toy Regression Data Homescedastic (n=1000)\")\n",
    "\n",
    "    # Polynomial function with heteroscedastic noise (default - used in most experiments)\n",
    "    x_train, y_train, x_grid, y_clean = generate_toy_regression(\n",
    "        n_train = 1000, \n",
    "        train_range=(-5,10), \n",
    "        noise_type='heteroscedastic',\n",
    "        type = \"sin\",\n",
    "        tau = tau,\n",
    "        distribution = \"laplace\"\n",
    "    )\n",
    "\n",
    "    plot_toy_data(x_train, y_train, x_grid, y_clean, title=\"Toy Regression Data Heteroscedastic (n=1000)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0500fe63",
   "metadata": {},
   "source": [
    "## Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d13134e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x254db7244b0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tau_values = [0.5, 1, 2, 2.5, 5]\n",
    "tau_values_bnn = [0.5,5]\n",
    "distributions = ['normal']\n",
    "function_types = ['linear', 'sin']\n",
    "n_train = 1000\n",
    "train_range = (-5,10)\n",
    "grid_points = 1500\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8621e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_mc_dropout_noise_level_experiment(\n",
    "    generate_toy_regression,\n",
    "    function_types=['linear'],\n",
    "    noise_type='heteroscedastic',\n",
    "    tau_values = [0.5, 1],\n",
    "    distributions=distributions,\n",
    "    n_train=n_train,\n",
    "    train_range=train_range,\n",
    "    grid_points=grid_points,\n",
    "    seed=seed,\n",
    "    beta=0.5,\n",
    "    lr=1e-3,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5e0729",
   "metadata": {},
   "source": [
    "# MC Droput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfee903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run noise level experiments for MC Dropout\n",
    "# This will loop through tau values, distributions, and function types\n",
    "\n",
    "## hetero ###\n",
    "\n",
    "run_mc_dropout_noise_level_experiment(\n",
    "    generate_toy_regression,\n",
    "    function_types=['linear', 'sin'],\n",
    "    noise_type='heteroscedastic',\n",
    "    tau_values=tau_values,\n",
    "    distributions=distributions,\n",
    "    n_train=n_train,\n",
    "    train_range=train_range,\n",
    "    grid_points=grid_points,\n",
    "    seed=seed,\n",
    "    beta=0.5,\n",
    "    lr=1e-3,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "## homo ###\n",
    "\n",
    "run_mc_dropout_noise_level_experiment(\n",
    "    generate_toy_regression,\n",
    "    function_types=function_types,\n",
    "    noise_type='homoscedastic',\n",
    "    tau_values=tau_values,\n",
    "    distributions=distributions,\n",
    "    n_train=n_train,\n",
    "    train_range=train_range,\n",
    "    grid_points=grid_points,\n",
    "    seed=seed,\n",
    "    beta=0.5,\n",
    "    lr=1e-3,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0876c45",
   "metadata": {},
   "source": [
    "## Deep Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7a41cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep Ensemble\n",
    "run_deep_ensemble_noise_level_experiment(\n",
    "    generate_toy_regression,\n",
    "    function_types=function_types,\n",
    "    noise_type='heteroscedastic',\n",
    "    tau_values=tau_values,\n",
    "    distributions=distributions,\n",
    "    n_train=n_train,\n",
    "    train_range=train_range,\n",
    "    grid_points=grid_points,\n",
    "    seed=seed,\n",
    "    beta=0.5,\n",
    "    batch_size=32,\n",
    ")\n",
    "\n",
    "run_deep_ensemble_noise_level_experiment(\n",
    "    generate_toy_regression,\n",
    "    function_types=function_types,\n",
    "    noise_type='homoscedastic',\n",
    "    tau_values=tau_values,\n",
    "    distributions=distributions,\n",
    "    n_train=n_train,\n",
    "    train_range=train_range,\n",
    "    grid_points=grid_points,\n",
    "    seed=seed,\n",
    "    beta=0.5,\n",
    "    batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3956f45",
   "metadata": {},
   "source": [
    "## BAMLLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c348bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "################################################################################\n",
      "# Function Type: Linear (linear) - Distribution: normal - BAMLSS\n",
      "################################################################################\n",
      "\n",
      "Using CPU parallelization with 2 workers (BAMLSS is CPU-only)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# BAMLSS\n",
    "run_bamlss_noise_level_experiment(\n",
    "    generate_toy_regression,\n",
    "    function_types=function_types,\n",
    "    noise_type='heteroscedastic',\n",
    "    tau_values=tau_values_bnn,\n",
    "    distributions=distributions,\n",
    "    n_train=n_train,\n",
    "    train_range=train_range,\n",
    "    grid_points=grid_points,\n",
    "    seed=seed,\n",
    "    n_iter=12000,\n",
    "    burnin=2000,\n",
    "    thin=10,\n",
    "    nsamples=1000\n",
    ")\n",
    "\n",
    "\n",
    "run_bamlss_noise_level_experiment(\n",
    "    generate_toy_regression,\n",
    "    function_types=function_types,\n",
    "    noise_type='homoscedastic',\n",
    "    tau_values=tau_values_bnn,\n",
    "    distributions=distributions,\n",
    "    n_train=n_train,\n",
    "    train_range=train_range,\n",
    "    grid_points=grid_points,\n",
    "    seed=seed,\n",
    "    n_iter=12000,\n",
    "    burnin=2000,\n",
    "    thin=10,\n",
    "    nsamples=1000\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbb3a84",
   "metadata": {},
   "source": [
    "## BNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476b18de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BNN\n",
    "run_bnn_noise_level_experiment(\n",
    "    generate_toy_regression,\n",
    "    function_types=['linear', 'sin'],\n",
    "    noise_type='heteroscedastic',\n",
    "    tau_values=tau_values_bnn,\n",
    "    distributions=['normal'],\n",
    "    n_train=1000,\n",
    "    train_range=(-5, 10),\n",
    "    grid_points=1000,\n",
    "    seed=42,\n",
    "    hidden_width=16,\n",
    "    weight_scale=1.0,\n",
    "    warmup=500,\n",
    "    samples=500,\n",
    "    chains=4\n",
    ")\n",
    "\n",
    "run_bnn_noise_level_experiment(\n",
    "    generate_toy_regression,\n",
    "    function_types=['linear', 'sin'],\n",
    "    noise_type='homoscedastic',\n",
    "    tau_values= tau_values_bnn,\n",
    "    distributions=['normal'],\n",
    "    n_train=1000,\n",
    "    train_range=(-5, 10),\n",
    "    grid_points=1000,\n",
    "    seed=42,\n",
    "    hidden_width=16,\n",
    "    weight_scale=1.0,\n",
    "    warmup=500,\n",
    "    samples=500,\n",
    "    chains=4\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
