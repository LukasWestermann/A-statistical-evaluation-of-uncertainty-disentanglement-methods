{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Packages\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from typing import Tuple\n",
        "import sys\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "import os\n",
        "import pyro\n",
        "\n",
        "# Add parent directory to path to import Models\n",
        "# This works for notebooks in the Experiments folder\n",
        "project_root = Path.cwd().parent if Path.cwd().name == 'Experiments' else Path.cwd()\n",
        "sys.path.insert(0, str(project_root))\n",
        "\n",
        "# Setup results directory\n",
        "results_dir = project_root / \"results\" / \"ood_parameter_comparison\"\n",
        "results_dir.mkdir(parents=True, exist_ok=True)\n",
        "plots_dir = results_dir / \"plots\"\n",
        "plots_dir.mkdir(exist_ok=True)\n",
        "stats_dir = results_dir / \"statistics\"\n",
        "stats_dir.mkdir(exist_ok=True)\n",
        "\n",
        "print(f\"Results will be saved to: {results_dir}\")\n",
        "\n",
        "# Import from Models folder\n",
        "from Models.MC_Dropout import (\n",
        "    MCDropoutRegressor,\n",
        "    train_model,\n",
        "    mc_dropout_predict,\n",
        "    gaussian_nll,\n",
        "    beta_nll,\n",
        "    plot_toy_data,\n",
        "    plot_uncertainties,\n",
        "    normalize_x,\n",
        "    normalize_x_data\n",
        ")\n",
        "\n",
        "from Models.Deep_Ensemble import (\n",
        "    train_ensemble_deep,\n",
        "    ensemble_predict_deep\n",
        ")\n",
        "\n",
        "from utils.device import get_device\n",
        "from utils.plotting import (\n",
        "    plot_toy_data, \n",
        "    plot_uncertainties_ood,\n",
        "    plot_uncertainties_ood_normalized,\n",
        "    plot_uncertainties_entropy_ood,\n",
        "    plot_uncertainties_entropy_ood_normalized,\n",
        "    plot_entropy_lines_ood\n",
        ")\n",
        "import utils.results_save as results_save_module\n",
        "from utils.results_save import save_plot, save_statistics, save_model_outputs\n",
        "\n",
        "# Import OOD helper functions\n",
        "from utils.ood_experiments import (\n",
        "    generate_data_with_ood,\n",
        "    compute_and_save_statistics_ood,\n",
        "    compute_and_save_statistics_entropy_ood\n",
        ")\n",
        "\n",
        "# Import entropy uncertainty functions\n",
        "from utils.entropy_uncertainty import entropy_uncertainty_analytical\n",
        "\n",
        "# Import metrics functions\n",
        "from utils.metrics import (\n",
        "    compute_predictive_aggregation,\n",
        "    compute_gaussian_nll,\n",
        "    compute_crps_gaussian,\n",
        "    compute_true_noise_variance,\n",
        "    compute_uncertainty_disentanglement\n",
        ")\n",
        "\n",
        "# Set the module-level directories for results_save\n",
        "results_save_module.plots_dir = plots_dir\n",
        "results_save_module.stats_dir = stats_dir\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Device Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = get_device()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate Toy Datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Reproducibility\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "# ----- Data generation for linear function with homo/heteroscedastic noise -----\n",
        "def generate_toy_regression(n_train=1000, train_range=(0.0, 10.0), train_ranges=None,\n",
        "                           ood_ranges=None, grid_points=1000, noise_type='heteroscedastic', type = \"linear\"):\n",
        "    \"\"\"\n",
        "    Generate toy regression data with support for multiple training ranges and OOD regions.\n",
        "    \n",
        "    Args:\n",
        "        n_train: Number of training samples\n",
        "        train_range: Single training range tuple (min, max) - for backward compatibility\n",
        "        train_ranges: List of training range tuples [(min1, max1), (min2, max2), ...]\n",
        "                     If provided, overrides train_range. Samples are distributed proportionally.\n",
        "        ood_ranges: List of OOD range tuples [(min1, max1), (min2, max2), ...]\n",
        "                   If None, OOD is automatically everything NOT in training ranges\n",
        "        grid_points: Number of grid points for evaluation\n",
        "        noise_type: 'homoscedastic' or 'heteroscedastic'\n",
        "        type: 'linear' or 'sin'\n",
        "    \n",
        "    Returns:\n",
        "        (x_train, y_train, x_grid, y_grid_clean, ood_mask)\n",
        "    \"\"\"\n",
        "    # Handle train_ranges: if provided, use it; otherwise use train_range as single range\n",
        "    if train_ranges is None:\n",
        "        train_ranges = [train_range]\n",
        "    else:\n",
        "        # train_ranges provided, ignore train_range\n",
        "        pass\n",
        "    \n",
        "    # Sample training data proportionally from each training range\n",
        "    # Calculate total width of all training ranges\n",
        "    total_width = sum([r[1] - r[0] for r in train_ranges])\n",
        "    \n",
        "    # Sample from each range proportionally\n",
        "    x_train_list = []\n",
        "    samples_allocated = 0\n",
        "    for idx, train_r in enumerate(train_ranges):\n",
        "        low, high = train_r\n",
        "        range_width = high - low\n",
        "        # Number of samples proportional to range width\n",
        "        if idx == len(train_ranges) - 1:\n",
        "            # Last range gets remaining samples to ensure exact total\n",
        "            n_samples = n_train - samples_allocated\n",
        "        else:\n",
        "            n_samples = int(n_train * range_width / total_width)\n",
        "            samples_allocated += n_samples\n",
        "        x_train_range = np.random.uniform(low, high, size=(n_samples, 1))\n",
        "        x_train_list.append(x_train_range)\n",
        "    \n",
        "    x_train = np.vstack(x_train_list)\n",
        "    # Shuffle to mix samples from different ranges\n",
        "    indices = np.random.permutation(len(x_train))\n",
        "    x_train = x_train[indices]\n",
        "    \n",
        "    if type == \"linear\":\n",
        "        # Linear function: f(x) = 0.7x + 0.5\n",
        "        f_clean = lambda x: 0.7 * x + 0.5\n",
        "        y_clean_train = f_clean(x_train)\n",
        "    elif type == \"sin\":\n",
        "        f_clean = lambda x:  x * np.sin(x) + x\n",
        "        y_clean_train = f_clean(x_train)\n",
        "    else:\n",
        "        raise ValueError(\"type must be 'linear', 'sin'\")\n",
        "\n",
        "    # Define noise variance σ²(x)\n",
        "    if noise_type == 'homoscedastic':\n",
        "        # Homoscedastic: σ(x) = 0.8\n",
        "        sigma = 2\n",
        "        sigma_train = np.full_like(x_train, sigma)\n",
        "    elif noise_type == 'heteroscedastic':\n",
        "        # Heteroscedastic: \n",
        "        sigma_train = np.abs(2.5 * np.sin(0.5*x_train +5))\n",
        "    else:\n",
        "        raise ValueError(\"noise_type must be 'homoscedastic' or 'heteroscedastic'\")\n",
        "    \n",
        "    # Generate noise: ε | x ~ N(0, σ²(x))\n",
        "    epsilon = np.random.normal(0.0, sigma_train, size=(n_train, 1))\n",
        "    y_train = y_clean_train + epsilon\n",
        "\n",
        "    # Determine grid extent: from min of all training/OOD ranges to max\n",
        "    all_ranges = train_ranges + (ood_ranges if ood_ranges else [])\n",
        "    grid_start = min([r[0] for r in all_ranges])\n",
        "    grid_end = max([r[1] for r in all_ranges])\n",
        "    \n",
        "    # Dense evaluation grid spanning all training and OOD regions\n",
        "    x_grid = np.linspace(grid_start, grid_end, grid_points).reshape(-1, 1)\n",
        "    y_grid_clean = f_clean(x_grid)\n",
        "    \n",
        "    # Create OOD mask: True for points NOT in any training range\n",
        "    # Everything outside training ranges is OOD (including gaps and explicit OOD ranges)\n",
        "    ood_mask = np.ones(len(x_grid), dtype=bool)  # Start with all True (OOD)\n",
        "    \n",
        "    # Mark training ranges as ID (False in ood_mask)\n",
        "    for train_r in train_ranges:\n",
        "        train_start, train_end = train_r\n",
        "        train_mask = (x_grid[:, 0] >= train_start) & (x_grid[:, 0] <= train_end)\n",
        "        ood_mask[train_mask] = False  # Training regions are ID, not OOD\n",
        "    \n",
        "    # If explicit ood_ranges provided, ensure they are marked as OOD\n",
        "    # (they might already be OOD if they're gaps, but this ensures they're marked)\n",
        "    if ood_ranges is not None:\n",
        "        for ood_range in ood_ranges:\n",
        "            ood_start, ood_end = ood_range\n",
        "            ood_mask |= (x_grid[:, 0] >= ood_start) & (x_grid[:, 0] <= ood_end)\n",
        "\n",
        "    return (x_train.astype(np.float32), y_train.astype(np.float32),\n",
        "            x_grid.astype(np.float32), y_grid_clean.astype(np.float32), ood_mask)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Set Parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Common parameters\n",
        "n_train = 1000\n",
        "train_range = (-5, 10)\n",
        "ood_ranges = [(10,15)]  # List of (min, max) tuples for OOD regions\n",
        "grid_points = 1000\n",
        "seed = 42\n",
        "noise_type = 'heteroscedastic'\n",
        "func_type = 'sin'  # or 'linear'\n",
        "function_name = \"Sinusoidal\" if func_type == 'sin' else \"Linear\"\n",
        "\n",
        "# Parameters to vary\n",
        "mc_samples_values = [10, 20, 50, 100, 200]  # MC Dropout forward passes\n",
        "dropout_p_values = [0.1, 0.2, 0.25]  # Can add more: [0.1, 0.2, 0.3]\n",
        "K_values = [5, 10, 15, 20, 25, 30]  # Deep Ensemble number of nets\n",
        "epochs_values = [100, 250, 500]  # Number of training epochs\n",
        "\n",
        "# Fixed training parameters\n",
        "beta = 0.5\n",
        "lr = 1e-3\n",
        "batch_size = 32\n",
        "\n",
        "torch.manual_seed(seed)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Helper Functions for Parameter Comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_single_mc_dropout_ood(generate_toy_regression_func, x_train, y_train, x_grid, y_grid_clean, ood_mask,\n",
        "                              p, mc_samples, beta, epochs, lr, batch_size, seed, \n",
        "                              function_name, noise_type, func_type, date, save_results=True):\n",
        "    \"\"\"Run a single MC Dropout OOD experiment and return results\"\"\"\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    \n",
        "    ds = TensorDataset(torch.from_numpy(x_train), torch.from_numpy(y_train))\n",
        "    loader = DataLoader(ds, batch_size=batch_size, shuffle=True)\n",
        "    \n",
        "    model = MCDropoutRegressor(p=p)\n",
        "    train_model(model, loader, epochs=epochs, lr=lr, loss_type='beta_nll', beta=beta)\n",
        "    \n",
        "    # Make predictions with raw arrays for metrics computation\n",
        "    result = mc_dropout_predict(model, x_grid, M=mc_samples, return_raw_arrays=True)\n",
        "    mu_pred, ale_var, epi_var, tot_var, (mu_samples, sigma2_samples) = result\n",
        "    \n",
        "    # Save model outputs for later recomputation\n",
        "    save_model_outputs(\n",
        "        mu_samples=mu_samples,\n",
        "        sigma2_samples=sigma2_samples,\n",
        "        x_grid=x_grid,\n",
        "        y_grid_clean=y_grid_clean,\n",
        "        x_train_subset=x_train,\n",
        "        y_train_subset=y_train,\n",
        "        model_name='MC_Dropout',\n",
        "        noise_type=noise_type,\n",
        "        func_type=func_type,\n",
        "        subfolder='ood_parameter_comparison',\n",
        "        dropout_p=p,\n",
        "        mc_samples=mc_samples,\n",
        "        date=date,\n",
        "        epochs=epochs\n",
        "    )\n",
        "    \n",
        "    # Split uncertainties by region\n",
        "    id_mask = ~ood_mask\n",
        "    \n",
        "    uncertainties_id = {\n",
        "        'ale': ale_var[id_mask] if ale_var.ndim == 1 else ale_var[id_mask].flatten(),\n",
        "        'epi': epi_var[id_mask] if epi_var.ndim == 1 else epi_var[id_mask].flatten(),\n",
        "        'tot': tot_var[id_mask] if tot_var.ndim == 1 else tot_var[id_mask].flatten()\n",
        "    }\n",
        "    \n",
        "    uncertainties_ood = {\n",
        "        'ale': ale_var[ood_mask] if ale_var.ndim == 1 else ale_var[ood_mask].flatten(),\n",
        "        'epi': epi_var[ood_mask] if epi_var.ndim == 1 else epi_var[ood_mask].flatten(),\n",
        "        'tot': tot_var[ood_mask] if tot_var.ndim == 1 else tot_var[ood_mask].flatten()\n",
        "    }\n",
        "    \n",
        "    uncertainties_combined = {\n",
        "        'ale': ale_var.flatten() if ale_var.ndim > 1 else ale_var,\n",
        "        'epi': epi_var.flatten() if epi_var.ndim > 1 else epi_var,\n",
        "        'tot': tot_var.flatten() if tot_var.ndim > 1 else tot_var\n",
        "    }\n",
        "    \n",
        "    # Compute MSE separately\n",
        "    mu_pred_flat = mu_pred.squeeze() if mu_pred.ndim > 1 else mu_pred\n",
        "    y_grid_clean_flat = y_grid_clean.squeeze() if y_grid_clean.ndim > 1 else y_grid_clean\n",
        "    \n",
        "    mse_id = np.mean((mu_pred_flat[id_mask] - y_grid_clean_flat[id_mask])**2)\n",
        "    mse_ood = np.mean((mu_pred_flat[ood_mask] - y_grid_clean_flat[ood_mask])**2)\n",
        "    mse_combined = np.mean((mu_pred_flat - y_grid_clean_flat)**2)\n",
        "    \n",
        "    # Compute predictive aggregation (μ*, σ*²)\n",
        "    mu_star, sigma2_star = compute_predictive_aggregation(mu_samples, sigma2_samples)\n",
        "    \n",
        "    # Compute true noise variance for grid points\n",
        "    true_noise_var = compute_true_noise_variance(x_grid, noise_type, func_type)\n",
        "    \n",
        "    # Compute NLL, CRPS, and disentanglement metrics for each region\n",
        "    nll_id = compute_gaussian_nll(y_grid_clean_flat[id_mask], mu_star[id_mask], sigma2_star[id_mask])\n",
        "    nll_ood = compute_gaussian_nll(y_grid_clean_flat[ood_mask], mu_star[ood_mask], sigma2_star[ood_mask])\n",
        "    nll_combined = compute_gaussian_nll(y_grid_clean_flat, mu_star, sigma2_star)\n",
        "    \n",
        "    crps_id = compute_crps_gaussian(y_grid_clean_flat[id_mask], mu_star[id_mask], sigma2_star[id_mask])\n",
        "    crps_ood = compute_crps_gaussian(y_grid_clean_flat[ood_mask], mu_star[ood_mask], sigma2_star[ood_mask])\n",
        "    crps_combined = compute_crps_gaussian(y_grid_clean_flat, mu_star, sigma2_star)\n",
        "    \n",
        "    disentangle_id = compute_uncertainty_disentanglement(\n",
        "        y_grid_clean_flat[id_mask], mu_star[id_mask],\n",
        "        ale_var[id_mask] if ale_var.ndim == 1 else ale_var[id_mask].flatten(),\n",
        "        epi_var[id_mask] if epi_var.ndim == 1 else epi_var[id_mask].flatten(),\n",
        "        true_noise_var[id_mask]\n",
        "    )\n",
        "    disentangle_ood = compute_uncertainty_disentanglement(\n",
        "        y_grid_clean_flat[ood_mask], mu_star[ood_mask],\n",
        "        ale_var[ood_mask] if ale_var.ndim == 1 else ale_var[ood_mask].flatten(),\n",
        "        epi_var[ood_mask] if epi_var.ndim == 1 else epi_var[ood_mask].flatten(),\n",
        "        true_noise_var[ood_mask]\n",
        "    )\n",
        "    disentangle_combined = compute_uncertainty_disentanglement(\n",
        "        y_grid_clean_flat, mu_star, ale_var.flatten() if ale_var.ndim > 1 else ale_var,\n",
        "        epi_var.flatten() if epi_var.ndim > 1 else epi_var, true_noise_var\n",
        "    )\n",
        "    \n",
        "    # Compute entropy-based uncertainties\n",
        "    entropy_results = entropy_uncertainty_analytical(mu_samples, sigma2_samples)\n",
        "    ale_entropy = entropy_results['aleatoric']\n",
        "    epi_entropy = entropy_results['epistemic']\n",
        "    tot_entropy = entropy_results['total']\n",
        "    \n",
        "    # Split entropy uncertainties by region\n",
        "    uncertainties_entropy_id = {\n",
        "        'ale': ale_entropy[id_mask] if ale_entropy.ndim == 1 else ale_entropy[id_mask].flatten(),\n",
        "        'epi': epi_entropy[id_mask] if epi_entropy.ndim == 1 else epi_entropy[id_mask].flatten(),\n",
        "        'tot': tot_entropy[id_mask] if tot_entropy.ndim == 1 else tot_entropy[id_mask].flatten()\n",
        "    }\n",
        "    \n",
        "    uncertainties_entropy_ood = {\n",
        "        'ale': ale_entropy[ood_mask] if ale_entropy.ndim == 1 else ale_entropy[ood_mask].flatten(),\n",
        "        'epi': epi_entropy[ood_mask] if epi_entropy.ndim == 1 else epi_entropy[ood_mask].flatten(),\n",
        "        'tot': tot_entropy[ood_mask] if tot_entropy.ndim == 1 else tot_entropy[ood_mask].flatten()\n",
        "    }\n",
        "    \n",
        "    uncertainties_entropy_combined = {\n",
        "        'ale': ale_entropy.flatten() if ale_entropy.ndim > 1 else ale_entropy,\n",
        "        'epi': epi_entropy.flatten() if epi_entropy.ndim > 1 else epi_entropy,\n",
        "        'tot': tot_entropy.flatten() if tot_entropy.ndim > 1 else tot_entropy\n",
        "    }\n",
        "    \n",
        "    # Save statistics if requested\n",
        "    if save_results:\n",
        "        compute_and_save_statistics_ood(\n",
        "            uncertainties_id, uncertainties_ood, uncertainties_combined,\n",
        "            mse_id, mse_ood, mse_combined,\n",
        "            function_name, noise_type, func_type, 'MC_Dropout',\n",
        "            date=date, dropout_p=p, mc_samples=mc_samples,\n",
        "            nll_id=nll_id, nll_ood=nll_ood, nll_combined=nll_combined,\n",
        "            crps_id=crps_id, crps_ood=crps_ood, crps_combined=crps_combined,\n",
        "            spearman_aleatoric_id=disentangle_id['spearman_aleatoric'],\n",
        "            spearman_aleatoric_ood=disentangle_ood['spearman_aleatoric'],\n",
        "            spearman_aleatoric_combined=disentangle_combined['spearman_aleatoric'],\n",
        "            spearman_epistemic_id=disentangle_id['spearman_epistemic'],\n",
        "            spearman_epistemic_ood=disentangle_ood['spearman_epistemic'],\n",
        "            spearman_epistemic_combined=disentangle_combined['spearman_epistemic']\n",
        "        )\n",
        "        \n",
        "        # Compute and save normalized entropy-based statistics\n",
        "        compute_and_save_statistics_entropy_ood(\n",
        "            uncertainties_entropy_id, uncertainties_entropy_ood, uncertainties_entropy_combined,\n",
        "            mse_id, mse_ood, mse_combined,\n",
        "            function_name, noise_type, func_type, 'MC_Dropout',\n",
        "            date=date, dropout_p=p, mc_samples=mc_samples,\n",
        "            nll_id=nll_id, nll_ood=nll_ood, nll_combined=nll_combined,\n",
        "            crps_id=crps_id, crps_ood=crps_ood, crps_combined=crps_combined,\n",
        "            spearman_aleatoric_id=disentangle_id['spearman_aleatoric'],\n",
        "            spearman_aleatoric_ood=disentangle_ood['spearman_aleatoric'],\n",
        "            spearman_aleatoric_combined=disentangle_combined['spearman_aleatoric'],\n",
        "            spearman_epistemic_id=disentangle_id['spearman_epistemic'],\n",
        "            spearman_epistemic_ood=disentangle_ood['spearman_epistemic'],\n",
        "            spearman_epistemic_combined=disentangle_combined['spearman_epistemic']\n",
        "        )\n",
        "        \n",
        "        # Plot std-based variance uncertainties\n",
        "        plot_uncertainties_ood(\n",
        "            x_train, y_train, x_grid, y_grid_clean,\n",
        "            mu_pred, ale_var, epi_var, tot_var, ood_mask,\n",
        "            title=f\"MC Dropout (p={p}, M={mc_samples}, E={epochs}) - Variance (Std)\",\n",
        "            noise_type=noise_type, func_type=func_type\n",
        "        )\n",
        "        \n",
        "        # Plot normalized variance-based uncertainties\n",
        "        plot_uncertainties_ood_normalized(\n",
        "            x_train, y_train, x_grid, y_grid_clean,\n",
        "            mu_pred, ale_var, epi_var, tot_var, ood_mask,\n",
        "            title=f\"MC Dropout (p={p}, M={mc_samples}, E={epochs}) - Normalized Variance\",\n",
        "            noise_type=noise_type, func_type=func_type,\n",
        "            scale_factor=1\n",
        "        )\n",
        "        \n",
        "        # Plot entropy-based uncertainties (as std-equivalent bands)\n",
        "        plot_uncertainties_entropy_ood(\n",
        "            x_train, y_train, x_grid, y_grid_clean,\n",
        "            mu_pred, ale_entropy, epi_entropy, tot_entropy, ood_mask,\n",
        "            title=f\"MC Dropout (p={p}, M={mc_samples}, E={epochs}) - Entropy (Std-Equivalent)\",\n",
        "            noise_type=noise_type, func_type=func_type\n",
        "        )\n",
        "        \n",
        "        # Plot normalized entropy-based uncertainties\n",
        "        plot_uncertainties_entropy_ood_normalized(\n",
        "            x_train, y_train, x_grid, y_grid_clean,\n",
        "            mu_pred, ale_entropy, epi_entropy, tot_entropy, ood_mask,\n",
        "            title=f\"MC Dropout (p={p}, M={mc_samples}, E={epochs}) - Normalized Entropy\",\n",
        "            noise_type=noise_type, func_type=func_type,\n",
        "            scale_factor=1\n",
        "        )\n",
        "        \n",
        "        # Plot entropy values directly as line plots (in nats)\n",
        "        plot_entropy_lines_ood(\n",
        "            x_train, y_train, x_grid, y_grid_clean,\n",
        "            mu_pred, ale_entropy, epi_entropy, tot_entropy, ood_mask,\n",
        "            title=f\"MC Dropout (p={p}, M={mc_samples}, E={epochs}) - Entropy Lines\",\n",
        "            noise_type=noise_type, func_type=func_type\n",
        "        )\n",
        "    \n",
        "    return {\n",
        "        'uncertainties_id': uncertainties_id,\n",
        "        'uncertainties_ood': uncertainties_ood,\n",
        "        'uncertainties_combined': uncertainties_combined,\n",
        "        'mse_id': mse_id,\n",
        "        'mse_ood': mse_ood,\n",
        "        'mse_combined': mse_combined,\n",
        "        'nll_id': nll_id,\n",
        "        'nll_ood': nll_ood,\n",
        "        'nll_combined': nll_combined,\n",
        "        'crps_id': crps_id,\n",
        "        'crps_ood': crps_ood,\n",
        "        'crps_combined': crps_combined,\n",
        "        'spearman_aleatoric_id': disentangle_id['spearman_aleatoric'],\n",
        "        'spearman_aleatoric_ood': disentangle_ood['spearman_aleatoric'],\n",
        "        'spearman_aleatoric_combined': disentangle_combined['spearman_aleatoric'],\n",
        "        'spearman_epistemic_id': disentangle_id['spearman_epistemic'],\n",
        "        'spearman_epistemic_ood': disentangle_ood['spearman_epistemic'],\n",
        "        'spearman_epistemic_combined': disentangle_combined['spearman_epistemic'],\n",
        "        'mu_pred': mu_pred,\n",
        "        'ale_var': ale_var,\n",
        "        'epi_var': epi_var,\n",
        "        'tot_var': tot_var,\n",
        "        'ale_entropy': ale_entropy,\n",
        "        'epi_entropy': epi_entropy,\n",
        "        'tot_entropy': tot_entropy,\n",
        "        'uncertainties_entropy_id': uncertainties_entropy_id,\n",
        "        'uncertainties_entropy_ood': uncertainties_entropy_ood,\n",
        "        'uncertainties_entropy_combined': uncertainties_entropy_combined\n",
        "    }\n",
        "\n",
        "\n",
        "def run_single_deep_ensemble_ood(generate_toy_regression_func, x_train, y_train, x_grid, y_grid_clean, ood_mask,\n",
        "                                 K, beta, batch_size, epochs, seed,\n",
        "                                 function_name, noise_type, func_type, date, save_results=True):\n",
        "    \"\"\"Run a single Deep Ensemble OOD experiment and return results\"\"\"\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    \n",
        "    x_mean, x_std = normalize_x(x_train)\n",
        "    x_train_norm = normalize_x_data(x_train, x_mean, x_std)\n",
        "    x_grid_norm = normalize_x_data(x_grid, x_mean, x_std)\n",
        "    \n",
        "    ensemble = train_ensemble_deep(\n",
        "        x_train_norm, y_train,\n",
        "        batch_size=batch_size, K=K,\n",
        "        loss_type='beta_nll', beta=beta, parallel=True, epochs=epochs\n",
        "    )\n",
        "    \n",
        "    # Make predictions with raw arrays for metrics computation\n",
        "    result = ensemble_predict_deep(ensemble, x_grid_norm, return_raw_arrays=True)\n",
        "    mu_pred, ale_var, epi_var, tot_var, (mu_samples, sigma2_samples) = result\n",
        "    \n",
        "    # Save model outputs for later recomputation\n",
        "    save_model_outputs(\n",
        "        mu_samples=mu_samples,\n",
        "        sigma2_samples=sigma2_samples,\n",
        "        x_grid=x_grid,\n",
        "        y_grid_clean=y_grid_clean,\n",
        "        x_train_subset=x_train,\n",
        "        y_train_subset=y_train,\n",
        "        model_name='Deep_Ensemble',\n",
        "        noise_type=noise_type,\n",
        "        func_type=func_type,\n",
        "        subfolder='ood_parameter_comparison',\n",
        "        n_nets=K,\n",
        "        date=date,\n",
        "        epochs=epochs\n",
        "    )\n",
        "    \n",
        "    # Split uncertainties by region\n",
        "    id_mask = ~ood_mask\n",
        "    \n",
        "    uncertainties_id = {\n",
        "        'ale': ale_var[id_mask] if ale_var.ndim == 1 else ale_var[id_mask].flatten(),\n",
        "        'epi': epi_var[id_mask] if epi_var.ndim == 1 else epi_var[id_mask].flatten(),\n",
        "        'tot': tot_var[id_mask] if tot_var.ndim == 1 else tot_var[id_mask].flatten()\n",
        "    }\n",
        "    \n",
        "    uncertainties_ood = {\n",
        "        'ale': ale_var[ood_mask] if ale_var.ndim == 1 else ale_var[ood_mask].flatten(),\n",
        "        'epi': epi_var[ood_mask] if epi_var.ndim == 1 else epi_var[ood_mask].flatten(),\n",
        "        'tot': tot_var[ood_mask] if tot_var.ndim == 1 else tot_var[ood_mask].flatten()\n",
        "    }\n",
        "    \n",
        "    uncertainties_combined = {\n",
        "        'ale': ale_var.flatten() if ale_var.ndim > 1 else ale_var,\n",
        "        'epi': epi_var.flatten() if epi_var.ndim > 1 else epi_var,\n",
        "        'tot': tot_var.flatten() if tot_var.ndim > 1 else tot_var\n",
        "    }\n",
        "    \n",
        "    # Compute MSE separately\n",
        "    mu_pred_flat = mu_pred.squeeze() if mu_pred.ndim > 1 else mu_pred\n",
        "    y_grid_clean_flat = y_grid_clean.squeeze() if y_grid_clean.ndim > 1 else y_grid_clean\n",
        "    \n",
        "    mse_id = np.mean((mu_pred_flat[id_mask] - y_grid_clean_flat[id_mask])**2)\n",
        "    mse_ood = np.mean((mu_pred_flat[ood_mask] - y_grid_clean_flat[ood_mask])**2)\n",
        "    mse_combined = np.mean((mu_pred_flat - y_grid_clean_flat)**2)\n",
        "    \n",
        "    # Compute predictive aggregation (μ*, σ*²)\n",
        "    mu_star, sigma2_star = compute_predictive_aggregation(mu_samples, sigma2_samples)\n",
        "    \n",
        "    # Compute true noise variance for grid points\n",
        "    true_noise_var = compute_true_noise_variance(x_grid, noise_type, func_type)\n",
        "    \n",
        "    # Compute NLL, CRPS, and disentanglement metrics for each region\n",
        "    nll_id = compute_gaussian_nll(y_grid_clean_flat[id_mask], mu_star[id_mask], sigma2_star[id_mask])\n",
        "    nll_ood = compute_gaussian_nll(y_grid_clean_flat[ood_mask], mu_star[ood_mask], sigma2_star[ood_mask])\n",
        "    nll_combined = compute_gaussian_nll(y_grid_clean_flat, mu_star, sigma2_star)\n",
        "    \n",
        "    crps_id = compute_crps_gaussian(y_grid_clean_flat[id_mask], mu_star[id_mask], sigma2_star[id_mask])\n",
        "    crps_ood = compute_crps_gaussian(y_grid_clean_flat[ood_mask], mu_star[ood_mask], sigma2_star[ood_mask])\n",
        "    crps_combined = compute_crps_gaussian(y_grid_clean_flat, mu_star, sigma2_star)\n",
        "    \n",
        "    disentangle_id = compute_uncertainty_disentanglement(\n",
        "        y_grid_clean_flat[id_mask], mu_star[id_mask],\n",
        "        ale_var[id_mask] if ale_var.ndim == 1 else ale_var[id_mask].flatten(),\n",
        "        epi_var[id_mask] if epi_var.ndim == 1 else epi_var[id_mask].flatten(),\n",
        "        true_noise_var[id_mask]\n",
        "    )\n",
        "    disentangle_ood = compute_uncertainty_disentanglement(\n",
        "        y_grid_clean_flat[ood_mask], mu_star[ood_mask],\n",
        "        ale_var[ood_mask] if ale_var.ndim == 1 else ale_var[ood_mask].flatten(),\n",
        "        epi_var[ood_mask] if epi_var.ndim == 1 else epi_var[ood_mask].flatten(),\n",
        "        true_noise_var[ood_mask]\n",
        "    )\n",
        "    disentangle_combined = compute_uncertainty_disentanglement(\n",
        "        y_grid_clean_flat, mu_star, ale_var.flatten() if ale_var.ndim > 1 else ale_var,\n",
        "        epi_var.flatten() if epi_var.ndim > 1 else epi_var, true_noise_var\n",
        "    )\n",
        "    \n",
        "    # Compute entropy-based uncertainties\n",
        "    entropy_results = entropy_uncertainty_analytical(mu_samples, sigma2_samples)\n",
        "    ale_entropy = entropy_results['aleatoric']\n",
        "    epi_entropy = entropy_results['epistemic']\n",
        "    tot_entropy = entropy_results['total']\n",
        "    \n",
        "    # Split entropy uncertainties by region\n",
        "    uncertainties_entropy_id = {\n",
        "        'ale': ale_entropy[id_mask] if ale_entropy.ndim == 1 else ale_entropy[id_mask].flatten(),\n",
        "        'epi': epi_entropy[id_mask] if epi_entropy.ndim == 1 else epi_entropy[id_mask].flatten(),\n",
        "        'tot': tot_entropy[id_mask] if tot_entropy.ndim == 1 else tot_entropy[id_mask].flatten()\n",
        "    }\n",
        "    \n",
        "    uncertainties_entropy_ood = {\n",
        "        'ale': ale_entropy[ood_mask] if ale_entropy.ndim == 1 else ale_entropy[ood_mask].flatten(),\n",
        "        'epi': epi_entropy[ood_mask] if epi_entropy.ndim == 1 else epi_entropy[ood_mask].flatten(),\n",
        "        'tot': tot_entropy[ood_mask] if tot_entropy.ndim == 1 else tot_entropy[ood_mask].flatten()\n",
        "    }\n",
        "    \n",
        "    uncertainties_entropy_combined = {\n",
        "        'ale': ale_entropy.flatten() if ale_entropy.ndim > 1 else ale_entropy,\n",
        "        'epi': epi_entropy.flatten() if epi_entropy.ndim > 1 else epi_entropy,\n",
        "        'tot': tot_entropy.flatten() if tot_entropy.ndim > 1 else tot_entropy\n",
        "    }\n",
        "    \n",
        "    # Save statistics if requested\n",
        "    if save_results:\n",
        "        compute_and_save_statistics_ood(\n",
        "            uncertainties_id, uncertainties_ood, uncertainties_combined,\n",
        "            mse_id, mse_ood, mse_combined,\n",
        "            function_name, noise_type, func_type, 'Deep_Ensemble',\n",
        "            date=date, n_nets=K,\n",
        "            nll_id=nll_id, nll_ood=nll_ood, nll_combined=nll_combined,\n",
        "            crps_id=crps_id, crps_ood=crps_ood, crps_combined=crps_combined,\n",
        "            spearman_aleatoric_id=disentangle_id['spearman_aleatoric'],\n",
        "            spearman_aleatoric_ood=disentangle_ood['spearman_aleatoric'],\n",
        "            spearman_aleatoric_combined=disentangle_combined['spearman_aleatoric'],\n",
        "            spearman_epistemic_id=disentangle_id['spearman_epistemic'],\n",
        "            spearman_epistemic_ood=disentangle_ood['spearman_epistemic'],\n",
        "            spearman_epistemic_combined=disentangle_combined['spearman_epistemic']\n",
        "        )\n",
        "        \n",
        "        # Compute and save normalized entropy-based statistics\n",
        "        compute_and_save_statistics_entropy_ood(\n",
        "            uncertainties_entropy_id, uncertainties_entropy_ood, uncertainties_entropy_combined,\n",
        "            mse_id, mse_ood, mse_combined,\n",
        "            function_name, noise_type, func_type, 'Deep_Ensemble',\n",
        "            date=date, n_nets=K,\n",
        "            nll_id=nll_id, nll_ood=nll_ood, nll_combined=nll_combined,\n",
        "            crps_id=crps_id, crps_ood=crps_ood, crps_combined=crps_combined,\n",
        "            spearman_aleatoric_id=disentangle_id['spearman_aleatoric'],\n",
        "            spearman_aleatoric_ood=disentangle_ood['spearman_aleatoric'],\n",
        "            spearman_aleatoric_combined=disentangle_combined['spearman_aleatoric'],\n",
        "            spearman_epistemic_id=disentangle_id['spearman_epistemic'],\n",
        "            spearman_epistemic_ood=disentangle_ood['spearman_epistemic'],\n",
        "            spearman_epistemic_combined=disentangle_combined['spearman_epistemic']\n",
        "        )\n",
        "        \n",
        "        # Plot std-based variance uncertainties\n",
        "        plot_uncertainties_ood(\n",
        "            x_train, y_train, x_grid, y_grid_clean,\n",
        "            mu_pred, ale_var, epi_var, tot_var, ood_mask,\n",
        "            title=f\"Deep Ensemble (K={K}, E={epochs}) - Variance (Std)\",\n",
        "            noise_type=noise_type, func_type=func_type\n",
        "        )\n",
        "        \n",
        "        # Plot normalized variance-based uncertainties\n",
        "        plot_uncertainties_ood_normalized(\n",
        "            x_train, y_train, x_grid, y_grid_clean,\n",
        "            mu_pred, ale_var, epi_var, tot_var, ood_mask,\n",
        "            title=f\"Deep Ensemble (K={K}, E={epochs}) - Normalized Variance\",\n",
        "            noise_type=noise_type, func_type=func_type,\n",
        "            scale_factor=1\n",
        "        )\n",
        "        \n",
        "        # Plot entropy-based uncertainties (as std-equivalent bands)\n",
        "        plot_uncertainties_entropy_ood(\n",
        "            x_train, y_train, x_grid, y_grid_clean,\n",
        "            mu_pred, ale_entropy, epi_entropy, tot_entropy, ood_mask,\n",
        "            title=f\"Deep Ensemble (K={K}, E={epochs}) - Entropy (Std-Equivalent)\",\n",
        "            noise_type=noise_type, func_type=func_type\n",
        "        )\n",
        "        \n",
        "        # Plot normalized entropy-based uncertainties\n",
        "        plot_uncertainties_entropy_ood_normalized(\n",
        "            x_train, y_train, x_grid, y_grid_clean,\n",
        "            mu_pred, ale_entropy, epi_entropy, tot_entropy, ood_mask,\n",
        "            title=f\"Deep Ensemble (K={K}, E={epochs}) - Normalized Entropy\",\n",
        "            noise_type=noise_type, func_type=func_type,\n",
        "            scale_factor=1\n",
        "        )\n",
        "        \n",
        "        # Plot entropy values directly as line plots (in nats)\n",
        "        plot_entropy_lines_ood(\n",
        "            x_train, y_train, x_grid, y_grid_clean,\n",
        "            mu_pred, ale_entropy, epi_entropy, tot_entropy, ood_mask,\n",
        "            title=f\"Deep Ensemble (K={K}, E={epochs}) - Entropy Lines\",\n",
        "            noise_type=noise_type, func_type=func_type\n",
        "        )\n",
        "    \n",
        "    return {\n",
        "        'uncertainties_id': uncertainties_id,\n",
        "        'uncertainties_ood': uncertainties_ood,\n",
        "        'uncertainties_combined': uncertainties_combined,\n",
        "        'mse_id': mse_id,\n",
        "        'mse_ood': mse_ood,\n",
        "        'mse_combined': mse_combined,\n",
        "        'nll_id': nll_id,\n",
        "        'nll_ood': nll_ood,\n",
        "        'nll_combined': nll_combined,\n",
        "        'crps_id': crps_id,\n",
        "        'crps_ood': crps_ood,\n",
        "        'crps_combined': crps_combined,\n",
        "        'spearman_aleatoric_id': disentangle_id['spearman_aleatoric'],\n",
        "        'spearman_aleatoric_ood': disentangle_ood['spearman_aleatoric'],\n",
        "        'spearman_aleatoric_combined': disentangle_combined['spearman_aleatoric'],\n",
        "        'spearman_epistemic_id': disentangle_id['spearman_epistemic'],\n",
        "        'spearman_epistemic_ood': disentangle_ood['spearman_epistemic'],\n",
        "        'spearman_epistemic_combined': disentangle_combined['spearman_epistemic'],\n",
        "        'mu_pred': mu_pred,\n",
        "        'ale_var': ale_var,\n",
        "        'epi_var': epi_var,\n",
        "        'tot_var': tot_var,\n",
        "        'ale_entropy': ale_entropy,\n",
        "        'epi_entropy': epi_entropy,\n",
        "        'tot_entropy': tot_entropy,\n",
        "        'uncertainties_entropy_id': uncertainties_entropy_id,\n",
        "        'uncertainties_entropy_ood': uncertainties_entropy_ood,\n",
        "        'uncertainties_entropy_combined': uncertainties_entropy_combined\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate Data (Once)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate data once (same for all parameter variations)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "x_train, y_train, x_grid, y_grid_clean, ood_mask = generate_data_with_ood(\n",
        "    generate_toy_regression, n_train, train_range, ood_ranges,\n",
        "    grid_points, noise_type, func_type, seed\n",
        ")\n",
        "\n",
        "print(f\"Training range: {train_range}\")\n",
        "print(f\"OOD ranges: {ood_ranges}\")\n",
        "print(f\"Grid spans: [{x_grid[0, 0]:.2f}, {x_grid[-1, 0]:.2f}]\")\n",
        "print(f\"ID points: {np.sum(~ood_mask)}, OOD points: {np.sum(ood_mask)}\")\n",
        "print(f\"Function type: {function_name} ({func_type})\")\n",
        "print(f\"Noise type: {noise_type}\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## MC Dropout - Vary mc_samples\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate date for this experiment batch\n",
        "date = datetime.now().strftime('%Y%m%d')\n",
        "\n",
        "# Store results for comparison\n",
        "results_mc_dropout = {}\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(f\"MC Dropout Parameter Comparison - Varying mc_samples and epochs\")\n",
        "print(f\"{'='*80}\\n\")\n",
        "\n",
        "for p in dropout_p_values:\n",
        "    for mc_samples in mc_samples_values:\n",
        "        for epochs_val in epochs_values:\n",
        "            param_key = f\"p{p}_M{mc_samples}_E{epochs_val}\"\n",
        "            print(f\"\\n{'='*60}\")\n",
        "            print(f\"Testing: p={p}, mc_samples={mc_samples}, epochs={epochs_val}\")\n",
        "            print(f\"{'='*60}\")\n",
        "            \n",
        "            result = run_single_mc_dropout_ood(\n",
        "                generate_toy_regression, x_train, y_train, x_grid, y_grid_clean, ood_mask,\n",
        "                p=p, mc_samples=mc_samples, beta=beta, epochs=epochs_val, lr=lr, batch_size=batch_size,\n",
        "                seed=seed, function_name=function_name, noise_type=noise_type, func_type=func_type,\n",
        "                date=date, save_results=True\n",
        "            )\n",
        "            \n",
        "            results_mc_dropout[param_key] = result\n",
        "            \n",
        "            # Print summary\n",
        "            print(f\"  ID - Avg Ale: {np.mean(result['uncertainties_id']['ale']):.6f}, \"\n",
        "                  f\"Avg Epi: {np.mean(result['uncertainties_id']['epi']):.6f}, \"\n",
        "                  f\"MSE: {result['mse_id']:.6f}\")\n",
        "            print(f\"  OOD - Avg Ale: {np.mean(result['uncertainties_ood']['ale']):.6f}, \"\n",
        "                  f\"Avg Epi: {np.mean(result['uncertainties_ood']['epi']):.6f}, \"\n",
        "                  f\"MSE: {result['mse_ood']:.6f}\")\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"MC Dropout experiments completed!\")\n",
        "print(f\"{'='*80}\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## MC Dropout - Comparison Plots\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract data for plotting\n",
        "mc_samples_list = []\n",
        "epochs_list = []\n",
        "p_list = []\n",
        "avg_ale_id_list = []\n",
        "avg_epi_id_list = []\n",
        "avg_tot_id_list = []\n",
        "avg_ale_ood_list = []\n",
        "avg_epi_ood_list = []\n",
        "avg_tot_ood_list = []\n",
        "avg_ale_entropy_id_list = []\n",
        "avg_epi_entropy_id_list = []\n",
        "avg_tot_entropy_id_list = []\n",
        "avg_ale_entropy_ood_list = []\n",
        "avg_epi_entropy_ood_list = []\n",
        "avg_tot_entropy_ood_list = []\n",
        "mse_id_list = []\n",
        "mse_ood_list = []\n",
        "nll_id_list = []\n",
        "nll_ood_list = []\n",
        "crps_id_list = []\n",
        "crps_ood_list = []\n",
        "spearman_aleatoric_id_list = []\n",
        "spearman_aleatoric_ood_list = []\n",
        "spearman_epistemic_id_list = []\n",
        "spearman_epistemic_ood_list = []\n",
        "\n",
        "for param_key, result in results_mc_dropout.items():\n",
        "    # Extract p, mc_samples and epochs from param_key (format: \"p0.2_M20_E250\")\n",
        "    parts = param_key.split('_')\n",
        "    p_val = float(parts[0][1:])  # Extract number after 'p'\n",
        "    mc_samples_val = int(parts[1][1:])  # Extract number after 'M'\n",
        "    epochs_val = int(parts[2][1:])  # Extract number after 'E'\n",
        "    p_list.append(p_val)\n",
        "    mc_samples_list.append(mc_samples_val)\n",
        "    epochs_list.append(epochs_val)\n",
        "    \n",
        "    avg_ale_id_list.append(np.mean(result['uncertainties_id']['ale']))\n",
        "    avg_epi_id_list.append(np.mean(result['uncertainties_id']['epi']))\n",
        "    avg_tot_id_list.append(np.mean(result['uncertainties_id']['tot']))\n",
        "    \n",
        "    avg_ale_ood_list.append(np.mean(result['uncertainties_ood']['ale']))\n",
        "    avg_epi_ood_list.append(np.mean(result['uncertainties_ood']['epi']))\n",
        "    avg_tot_ood_list.append(np.mean(result['uncertainties_ood']['tot']))\n",
        "    \n",
        "    # Extract entropy-based uncertainties\n",
        "    avg_ale_entropy_id_list.append(np.mean(result['uncertainties_entropy_id']['ale']))\n",
        "    avg_epi_entropy_id_list.append(np.mean(result['uncertainties_entropy_id']['epi']))\n",
        "    avg_tot_entropy_id_list.append(np.mean(result['uncertainties_entropy_id']['tot']))\n",
        "    \n",
        "    avg_ale_entropy_ood_list.append(np.mean(result['uncertainties_entropy_ood']['ale']))\n",
        "    avg_epi_entropy_ood_list.append(np.mean(result['uncertainties_entropy_ood']['epi']))\n",
        "    avg_tot_entropy_ood_list.append(np.mean(result['uncertainties_entropy_ood']['tot']))\n",
        "    \n",
        "    mse_id_list.append(result['mse_id'])\n",
        "    mse_ood_list.append(result['mse_ood'])\n",
        "    nll_id_list.append(result['nll_id'])\n",
        "    nll_ood_list.append(result['nll_ood'])\n",
        "    crps_id_list.append(result['crps_id'])\n",
        "    crps_ood_list.append(result['crps_ood'])\n",
        "    spearman_aleatoric_id_list.append(result['spearman_aleatoric_id'])\n",
        "    spearman_aleatoric_ood_list.append(result['spearman_aleatoric_ood'])\n",
        "    spearman_epistemic_id_list.append(result['spearman_epistemic_id'])\n",
        "    spearman_epistemic_ood_list.append(result['spearman_epistemic_ood'])\n",
        "\n",
        "# Sort by mc_samples first, then by epochs, then by p\n",
        "sorted_indices = np.lexsort((p_list, epochs_list, mc_samples_list))\n",
        "p_list = [p_list[i] for i in sorted_indices]\n",
        "mc_samples_list = [mc_samples_list[i] for i in sorted_indices]\n",
        "epochs_list = [epochs_list[i] for i in sorted_indices]\n",
        "avg_ale_id_list = [avg_ale_id_list[i] for i in sorted_indices]\n",
        "avg_epi_id_list = [avg_epi_id_list[i] for i in sorted_indices]\n",
        "avg_tot_id_list = [avg_tot_id_list[i] for i in sorted_indices]\n",
        "avg_ale_ood_list = [avg_ale_ood_list[i] for i in sorted_indices]\n",
        "avg_epi_ood_list = [avg_epi_ood_list[i] for i in sorted_indices]\n",
        "avg_tot_ood_list = [avg_tot_ood_list[i] for i in sorted_indices]\n",
        "avg_ale_entropy_id_list = [avg_ale_entropy_id_list[i] for i in sorted_indices]\n",
        "avg_epi_entropy_id_list = [avg_epi_entropy_id_list[i] for i in sorted_indices]\n",
        "avg_tot_entropy_id_list = [avg_tot_entropy_id_list[i] for i in sorted_indices]\n",
        "avg_ale_entropy_ood_list = [avg_ale_entropy_ood_list[i] for i in sorted_indices]\n",
        "avg_epi_entropy_ood_list = [avg_epi_entropy_ood_list[i] for i in sorted_indices]\n",
        "avg_tot_entropy_ood_list = [avg_tot_entropy_ood_list[i] for i in sorted_indices]\n",
        "mse_id_list = [mse_id_list[i] for i in sorted_indices]\n",
        "mse_ood_list = [mse_ood_list[i] for i in sorted_indices]\n",
        "nll_id_list = [nll_id_list[i] for i in sorted_indices]\n",
        "nll_ood_list = [nll_ood_list[i] for i in sorted_indices]\n",
        "crps_id_list = [crps_id_list[i] for i in sorted_indices]\n",
        "crps_ood_list = [crps_ood_list[i] for i in sorted_indices]\n",
        "spearman_aleatoric_id_list = [spearman_aleatoric_id_list[i] for i in sorted_indices]\n",
        "spearman_aleatoric_ood_list = [spearman_aleatoric_ood_list[i] for i in sorted_indices]\n",
        "spearman_epistemic_id_list = [spearman_epistemic_id_list[i] for i in sorted_indices]\n",
        "spearman_epistemic_ood_list = [spearman_epistemic_ood_list[i] for i in sorted_indices]\n",
        "\n",
        "# Filter for first epoch value and first p value for mc_samples plots (to avoid multiple points per mc_samples)\n",
        "first_epoch = epochs_values[0]\n",
        "first_p = dropout_p_values[0]\n",
        "mask_first_epoch = [e == first_epoch for e in epochs_list]\n",
        "mask_first_p = [p == first_p for p in p_list]\n",
        "mask_filtered = [mask_first_epoch[i] and mask_first_p[i] for i in range(len(mask_first_epoch))]\n",
        "mc_samples_filtered = [mc_samples_list[i] for i in range(len(mc_samples_list)) if mask_filtered[i]]\n",
        "avg_ale_id_filtered = [avg_ale_id_list[i] for i in range(len(avg_ale_id_list)) if mask_filtered[i]]\n",
        "avg_epi_id_filtered = [avg_epi_id_list[i] for i in range(len(avg_epi_id_list)) if mask_filtered[i]]\n",
        "avg_tot_id_filtered = [avg_tot_id_list[i] for i in range(len(avg_tot_id_list)) if mask_filtered[i]]\n",
        "avg_ale_ood_filtered = [avg_ale_ood_list[i] for i in range(len(avg_ale_ood_list)) if mask_filtered[i]]\n",
        "avg_epi_ood_filtered = [avg_epi_ood_list[i] for i in range(len(avg_epi_ood_list)) if mask_filtered[i]]\n",
        "avg_tot_ood_filtered = [avg_tot_ood_list[i] for i in range(len(avg_tot_ood_list)) if mask_filtered[i]]\n",
        "avg_ale_entropy_id_filtered = [avg_ale_entropy_id_list[i] for i in range(len(avg_ale_entropy_id_list)) if mask_filtered[i]]\n",
        "avg_epi_entropy_id_filtered = [avg_epi_entropy_id_list[i] for i in range(len(avg_epi_entropy_id_list)) if mask_filtered[i]]\n",
        "avg_tot_entropy_id_filtered = [avg_tot_entropy_id_list[i] for i in range(len(avg_tot_entropy_id_list)) if mask_filtered[i]]\n",
        "avg_ale_entropy_ood_filtered = [avg_ale_entropy_ood_list[i] for i in range(len(avg_ale_entropy_ood_list)) if mask_filtered[i]]\n",
        "avg_epi_entropy_ood_filtered = [avg_epi_entropy_ood_list[i] for i in range(len(avg_epi_entropy_ood_list)) if mask_filtered[i]]\n",
        "avg_tot_entropy_ood_filtered = [avg_tot_entropy_ood_list[i] for i in range(len(avg_tot_entropy_ood_list)) if mask_filtered[i]]\n",
        "mse_id_filtered = [mse_id_list[i] for i in range(len(mse_id_list)) if mask_filtered[i]]\n",
        "mse_ood_filtered = [mse_ood_list[i] for i in range(len(mse_ood_list)) if mask_filtered[i]]\n",
        "nll_id_filtered = [nll_id_list[i] for i in range(len(nll_id_list)) if mask_filtered[i]]\n",
        "nll_ood_filtered = [nll_ood_list[i] for i in range(len(nll_ood_list)) if mask_filtered[i]]\n",
        "crps_id_filtered = [crps_id_list[i] for i in range(len(crps_id_list)) if mask_filtered[i]]\n",
        "crps_ood_filtered = [crps_ood_list[i] for i in range(len(crps_ood_list)) if mask_filtered[i]]\n",
        "spearman_aleatoric_id_filtered = [spearman_aleatoric_id_list[i] for i in range(len(spearman_aleatoric_id_list)) if mask_filtered[i]]\n",
        "spearman_aleatoric_ood_filtered = [spearman_aleatoric_ood_list[i] for i in range(len(spearman_aleatoric_ood_list)) if mask_filtered[i]]\n",
        "spearman_epistemic_id_filtered = [spearman_epistemic_id_list[i] for i in range(len(spearman_epistemic_id_list)) if mask_filtered[i]]\n",
        "spearman_epistemic_ood_filtered = [spearman_epistemic_ood_list[i] for i in range(len(spearman_epistemic_ood_list)) if mask_filtered[i]]\n",
        "avg_epi_id_filtered_plot = [avg_epi_id_list[i] for i in range(len(avg_epi_id_list)) if mask_filtered[i]]\n",
        "avg_epi_ood_filtered_plot = [avg_epi_ood_list[i] for i in range(len(avg_epi_ood_list)) if mask_filtered[i]]\n",
        "\n",
        "# Create comparison plots\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "# Plot 1: Average Uncertainties - ID region\n",
        "axes[0, 0].plot(mc_samples_filtered, avg_ale_id_filtered, 'o-', label='Aleatoric (ID)', color='green', linewidth=2, markersize=8)\n",
        "axes[0, 0].plot(mc_samples_filtered, avg_epi_id_filtered, 's-', label='Epistemic (ID)', color='orange', linewidth=2, markersize=8)\n",
        "axes[0, 0].plot(mc_samples_filtered, avg_tot_id_filtered, '^-', label='Total (ID)', color='blue', linewidth=2, markersize=8)\n",
        "axes[0, 0].set_xlabel('MC Samples', fontsize=12)\n",
        "axes[0, 0].set_ylabel('Average Uncertainty', fontsize=12)\n",
        "axes[0, 0].set_title(f'MC Dropout: Average Uncertainties (ID) vs MC Samples\\n{function_name} Function ({noise_type.capitalize()})', fontsize=13, fontweight='bold')\n",
        "axes[0, 0].legend(fontsize=10)\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "axes[0, 0].set_xticks(mc_samples_filtered)\n",
        "\n",
        "# Plot 2: Average Entropy Uncertainties - ID region\n",
        "axes[0, 1].plot(mc_samples_filtered, avg_ale_entropy_id_filtered, 'o-', label='Aleatoric Entropy (ID)', color='green', linewidth=2, markersize=8)\n",
        "axes[0, 1].plot(mc_samples_filtered, avg_epi_entropy_id_filtered, 's-', label='Epistemic Entropy (ID)', color='orange', linewidth=2, markersize=8)\n",
        "axes[0, 1].plot(mc_samples_filtered, avg_tot_entropy_id_filtered, '^-', label='Total Entropy (ID)', color='blue', linewidth=2, markersize=8)\n",
        "axes[0, 1].set_xlabel('MC Samples', fontsize=12)\n",
        "axes[0, 1].set_ylabel('Average Entropy Uncertainty', fontsize=12)\n",
        "axes[0, 1].set_title(f'MC Dropout: Average Entropy Uncertainties (ID) vs MC Samples\\n{function_name} Function ({noise_type.capitalize()})', fontsize=13, fontweight='bold')\n",
        "axes[0, 1].legend(fontsize=10)\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "axes[0, 1].set_xticks(mc_samples_filtered)\n",
        "\n",
        "# Plot 3: MSE comparison\n",
        "axes[1, 0].plot(mc_samples_filtered, mse_id_filtered, 'o-', label='MSE (ID)', color='blue', linewidth=2, markersize=8)\n",
        "axes[1, 0].plot(mc_samples_filtered, mse_ood_filtered, 's-', label='MSE (OOD)', color='red', linewidth=2, markersize=8)\n",
        "axes[1, 0].set_xlabel('MC Samples', fontsize=12)\n",
        "axes[1, 0].set_ylabel('MSE', fontsize=12)\n",
        "axes[1, 0].set_title(f'MC Dropout: MSE vs MC Samples\\n{function_name} Function ({noise_type.capitalize()})', fontsize=13, fontweight='bold')\n",
        "axes[1, 0].legend(fontsize=10)\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "axes[1, 0].set_yscale('log')\n",
        "axes[1, 0].set_xticks(mc_samples_filtered)\n",
        "\n",
        "# Plot 4: ID vs OOD comparison (bar chart for one parameter)\n",
        "x_pos = np.arange(len(mc_samples_filtered))\n",
        "width = 0.35\n",
        "axes[1, 1].bar(x_pos - width/2, avg_epi_id_filtered_plot, width, label='Epistemic (ID)', color='orange', alpha=0.7)\n",
        "axes[1, 1].bar(x_pos + width/2, avg_epi_ood_filtered_plot, width, label='Epistemic (OOD)', color='red', alpha=0.7)\n",
        "axes[1, 1].set_xlabel('MC Samples', fontsize=12)\n",
        "axes[1, 1].set_ylabel('Average Epistemic Uncertainty', fontsize=12)\n",
        "axes[1, 1].set_title(f'MC Dropout: Epistemic Uncertainty - ID vs OOD\\n{function_name} Function ({noise_type.capitalize()})', fontsize=13, fontweight='bold')\n",
        "axes[1, 1].set_xticks(x_pos)\n",
        "axes[1, 1].set_xticklabels(mc_samples_filtered)\n",
        "axes[1, 1].legend(fontsize=10)\n",
        "axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "plt.suptitle(f'MC Dropout Parameter Comparison: Varying MC Samples (p={dropout_p_values[0]}, epochs={epochs_values[0]})', \n",
        "             fontsize=14, fontweight='bold', y=0.995)\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save plot\n",
        "save_plot(fig, f\"MC_Dropout_mc_samples_comparison_{function_name}_{noise_type}\", \n",
        "          subfolder=f\"comparisons/{noise_type}/{func_type}\")\n",
        "plt.show()\n",
        "plt.close(fig)\n",
        "\n",
        "# Create plots showing epochs variation (for fixed mc_samples)\n",
        "# Group by mc_samples and plot epochs variation\n",
        "unique_mc_samples = sorted(set(mc_samples_list))\n",
        "fig_epochs, axes_epochs = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "for mc_val in unique_mc_samples:\n",
        "    # Filter data for this mc_samples value and first p value\n",
        "    mask = [ms == mc_val and p == first_p for ms, p in zip(mc_samples_list, p_list)]\n",
        "    epochs_subset = [epochs_list[i] for i in range(len(epochs_list)) if mask[i]]\n",
        "    ale_id_subset = [avg_ale_id_list[i] for i in range(len(avg_ale_id_list)) if mask[i]]\n",
        "    epi_id_subset = [avg_epi_id_list[i] for i in range(len(avg_epi_id_list)) if mask[i]]\n",
        "    tot_id_subset = [avg_tot_id_list[i] for i in range(len(avg_tot_id_list)) if mask[i]]\n",
        "    ale_entropy_id_subset = [avg_ale_entropy_id_list[i] for i in range(len(avg_ale_entropy_id_list)) if mask[i]]\n",
        "    epi_entropy_id_subset = [avg_epi_entropy_id_list[i] for i in range(len(avg_epi_entropy_id_list)) if mask[i]]\n",
        "    tot_entropy_id_subset = [avg_tot_entropy_id_list[i] for i in range(len(avg_tot_entropy_id_list)) if mask[i]]\n",
        "    ale_ood_subset = [avg_ale_ood_list[i] for i in range(len(avg_ale_ood_list)) if mask[i]]\n",
        "    epi_ood_subset = [avg_epi_ood_list[i] for i in range(len(avg_epi_ood_list)) if mask[i]]\n",
        "    tot_ood_subset = [avg_tot_ood_list[i] for i in range(len(avg_tot_ood_list)) if mask[i]]\n",
        "    mse_id_subset = [mse_id_list[i] for i in range(len(mse_id_list)) if mask[i]]\n",
        "    mse_ood_subset = [mse_ood_list[i] for i in range(len(mse_ood_list)) if mask[i]]\n",
        "    \n",
        "    # Sort by epochs\n",
        "    sorted_epochs_idx = np.argsort(epochs_subset)\n",
        "    epochs_subset = [epochs_subset[i] for i in sorted_epochs_idx]\n",
        "    ale_id_subset = [ale_id_subset[i] for i in sorted_epochs_idx]\n",
        "    epi_id_subset = [epi_id_subset[i] for i in sorted_epochs_idx]\n",
        "    tot_id_subset = [tot_id_subset[i] for i in sorted_epochs_idx]\n",
        "    ale_entropy_id_subset = [ale_entropy_id_subset[i] for i in sorted_epochs_idx]\n",
        "    epi_entropy_id_subset = [epi_entropy_id_subset[i] for i in sorted_epochs_idx]\n",
        "    tot_entropy_id_subset = [tot_entropy_id_subset[i] for i in sorted_epochs_idx]\n",
        "    ale_ood_subset = [ale_ood_subset[i] for i in sorted_epochs_idx]\n",
        "    epi_ood_subset = [epi_ood_subset[i] for i in sorted_epochs_idx]\n",
        "    tot_ood_subset = [tot_ood_subset[i] for i in sorted_epochs_idx]\n",
        "    mse_id_subset = [mse_id_subset[i] for i in sorted_epochs_idx]\n",
        "    mse_ood_subset = [mse_ood_subset[i] for i in sorted_epochs_idx]\n",
        "    \n",
        "    # Plot ID uncertainties vs epochs\n",
        "    axes_epochs[0, 0].plot(epochs_subset, ale_id_subset, 'o-', label=f'Aleatoric (M={mc_val})', linewidth=2, markersize=6)\n",
        "    axes_epochs[0, 0].plot(epochs_subset, epi_id_subset, 's-', label=f'Epistemic (M={mc_val})', linewidth=2, markersize=6)\n",
        "    \n",
        "    # Plot ID entropy uncertainties vs epochs\n",
        "    axes_epochs[0, 1].plot(epochs_subset, ale_entropy_id_subset, 'o-', label=f'Aleatoric Entropy (M={mc_val})', linewidth=2, markersize=6)\n",
        "    axes_epochs[0, 1].plot(epochs_subset, epi_entropy_id_subset, 's-', label=f'Epistemic Entropy (M={mc_val})', linewidth=2, markersize=6)\n",
        "    \n",
        "    # Plot MSE vs epochs\n",
        "    axes_epochs[1, 0].plot(epochs_subset, mse_id_subset, 'o-', label=f'MSE ID (M={mc_val})', linewidth=2, markersize=6)\n",
        "    axes_epochs[1, 0].plot(epochs_subset, mse_ood_subset, 's-', label=f'MSE OOD (M={mc_val})', linewidth=2, markersize=6)\n",
        "\n",
        "axes_epochs[0, 0].set_xlabel('Epochs', fontsize=12)\n",
        "axes_epochs[0, 0].set_ylabel('Average Uncertainty', fontsize=12)\n",
        "axes_epochs[0, 0].set_title(f'MC Dropout: Average Uncertainties (ID) vs Epochs\\n{function_name} Function ({noise_type.capitalize()})', fontsize=13, fontweight='bold')\n",
        "axes_epochs[0, 0].legend(fontsize=9, ncol=2)\n",
        "axes_epochs[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "axes_epochs[0, 1].set_xlabel('Epochs', fontsize=12)\n",
        "axes_epochs[0, 1].set_ylabel('Average Entropy Uncertainty', fontsize=12)\n",
        "axes_epochs[0, 1].set_title(f'MC Dropout: Average Entropy Uncertainties (ID) vs Epochs\\n{function_name} Function ({noise_type.capitalize()})', fontsize=13, fontweight='bold')\n",
        "axes_epochs[0, 1].legend(fontsize=9, ncol=2)\n",
        "axes_epochs[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "axes_epochs[1, 0].set_xlabel('Epochs', fontsize=12)\n",
        "axes_epochs[1, 0].set_ylabel('MSE', fontsize=12)\n",
        "axes_epochs[1, 0].set_title(f'MC Dropout: MSE vs Epochs\\n{function_name} Function ({noise_type.capitalize()})', fontsize=13, fontweight='bold')\n",
        "axes_epochs[1, 0].legend(fontsize=9, ncol=2)\n",
        "axes_epochs[1, 0].grid(True, alpha=0.3)\n",
        "axes_epochs[1, 0].set_yscale('log')\n",
        "\n",
        "# Plot comparison of epistemic uncertainty ID vs OOD for different epochs\n",
        "for mc_val in unique_mc_samples:\n",
        "    mask = [ms == mc_val for ms in mc_samples_list]\n",
        "    epochs_subset = [epochs_list[i] for i in range(len(epochs_list)) if mask[i]]\n",
        "    epi_id_subset = [avg_epi_id_list[i] for i in range(len(avg_epi_id_list)) if mask[i]]\n",
        "    epi_ood_subset = [avg_epi_ood_list[i] for i in range(len(avg_epi_ood_list)) if mask[i]]\n",
        "    sorted_epochs_idx = np.argsort(epochs_subset)\n",
        "    epochs_subset = [epochs_subset[i] for i in sorted_epochs_idx]\n",
        "    epi_id_subset = [epi_id_subset[i] for i in sorted_epochs_idx]\n",
        "    epi_ood_subset = [epi_ood_subset[i] for i in sorted_epochs_idx]\n",
        "    axes_epochs[1, 1].plot(epochs_subset, epi_id_subset, 'o-', label=f'Epistemic ID (M={mc_val})', linewidth=2, markersize=6)\n",
        "    axes_epochs[1, 1].plot(epochs_subset, epi_ood_subset, 's--', label=f'Epistemic OOD (M={mc_val})', linewidth=2, markersize=6)\n",
        "\n",
        "axes_epochs[1, 1].set_xlabel('Epochs', fontsize=12)\n",
        "axes_epochs[1, 1].set_ylabel('Average Epistemic Uncertainty', fontsize=12)\n",
        "axes_epochs[1, 1].set_title(f'MC Dropout: Epistemic Uncertainty - ID vs OOD\\n{function_name} Function ({noise_type.capitalize()})', fontsize=13, fontweight='bold')\n",
        "axes_epochs[1, 1].legend(fontsize=9, ncol=2)\n",
        "axes_epochs[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.suptitle(f'MC Dropout Parameter Comparison: Varying Epochs (p={dropout_p_values[0]})', \n",
        "             fontsize=14, fontweight='bold', y=0.995)\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save plot\n",
        "save_plot(fig_epochs, f\"MC_Dropout_epochs_comparison_{function_name}_{noise_type}\", \n",
        "          subfolder=f\"comparisons/{noise_type}/{func_type}\")\n",
        "plt.show()\n",
        "plt.close(fig_epochs)\n",
        "\n",
        "# Create metrics evolution plots (NLL, CRPS, Spearman) vs mc_samples\n",
        "fig_metrics, axes_metrics = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "# Plot 1: NLL vs mc_samples\n",
        "axes_metrics[0, 0].plot(mc_samples_filtered, nll_id_filtered, 'o-', label='NLL (ID)', color='blue', linewidth=2, markersize=8)\n",
        "axes_metrics[0, 0].plot(mc_samples_filtered, nll_ood_filtered, 's-', label='NLL (OOD)', color='red', linewidth=2, markersize=8)\n",
        "axes_metrics[0, 0].set_xlabel('MC Samples', fontsize=12)\n",
        "axes_metrics[0, 0].set_ylabel('NLL', fontsize=12)\n",
        "axes_metrics[0, 0].set_title(f'MC Dropout: NLL vs MC Samples\\n{function_name} Function ({noise_type.capitalize()})', fontsize=13, fontweight='bold')\n",
        "axes_metrics[0, 0].legend(fontsize=10)\n",
        "axes_metrics[0, 0].grid(True, alpha=0.3)\n",
        "axes_metrics[0, 0].set_xticks(mc_samples_filtered)\n",
        "\n",
        "# Plot 2: CRPS vs mc_samples\n",
        "axes_metrics[0, 1].plot(mc_samples_filtered, crps_id_filtered, 'o-', label='CRPS (ID)', color='blue', linewidth=2, markersize=8)\n",
        "axes_metrics[0, 1].plot(mc_samples_filtered, crps_ood_filtered, 's-', label='CRPS (OOD)', color='red', linewidth=2, markersize=8)\n",
        "axes_metrics[0, 1].set_xlabel('MC Samples', fontsize=12)\n",
        "axes_metrics[0, 1].set_ylabel('CRPS', fontsize=12)\n",
        "axes_metrics[0, 1].set_title(f'MC Dropout: CRPS vs MC Samples\\n{function_name} Function ({noise_type.capitalize()})', fontsize=13, fontweight='bold')\n",
        "axes_metrics[0, 1].legend(fontsize=10)\n",
        "axes_metrics[0, 1].grid(True, alpha=0.3)\n",
        "axes_metrics[0, 1].set_xticks(mc_samples_filtered)\n",
        "\n",
        "# Plot 3: Spearman Aleatoric vs mc_samples\n",
        "axes_metrics[1, 0].plot(mc_samples_filtered, spearman_aleatoric_id_filtered, 'o-', label='Spearman Aleatoric (ID)', color='green', linewidth=2, markersize=8)\n",
        "axes_metrics[1, 0].plot(mc_samples_filtered, spearman_aleatoric_ood_filtered, 's-', label='Spearman Aleatoric (OOD)', color='darkgreen', linewidth=2, markersize=8)\n",
        "axes_metrics[1, 0].set_xlabel('MC Samples', fontsize=12)\n",
        "axes_metrics[1, 0].set_ylabel('Spearman Correlation', fontsize=12)\n",
        "axes_metrics[1, 0].set_title(f'MC Dropout: Spearman Aleatoric vs MC Samples\\n{function_name} Function ({noise_type.capitalize()})', fontsize=13, fontweight='bold')\n",
        "axes_metrics[1, 0].legend(fontsize=10)\n",
        "axes_metrics[1, 0].grid(True, alpha=0.3)\n",
        "axes_metrics[1, 0].set_xticks(mc_samples_filtered)\n",
        "\n",
        "# Plot 4: Spearman Epistemic vs mc_samples\n",
        "axes_metrics[1, 1].plot(mc_samples_filtered, spearman_epistemic_id_filtered, 'o-', label='Spearman Epistemic (ID)', color='orange', linewidth=2, markersize=8)\n",
        "axes_metrics[1, 1].plot(mc_samples_filtered, spearman_epistemic_ood_filtered, 's-', label='Spearman Epistemic (OOD)', color='red', linewidth=2, markersize=8)\n",
        "axes_metrics[1, 1].set_xlabel('MC Samples', fontsize=12)\n",
        "axes_metrics[1, 1].set_ylabel('Spearman Correlation', fontsize=12)\n",
        "axes_metrics[1, 1].set_title(f'MC Dropout: Spearman Epistemic vs MC Samples\\n{function_name} Function ({noise_type.capitalize()})', fontsize=13, fontweight='bold')\n",
        "axes_metrics[1, 1].legend(fontsize=10)\n",
        "axes_metrics[1, 1].grid(True, alpha=0.3)\n",
        "axes_metrics[1, 1].set_xticks(mc_samples_filtered)\n",
        "\n",
        "plt.suptitle(f'MC Dropout Parameter Comparison: Metrics vs MC Samples (p={dropout_p_values[0]}, epochs={epochs_values[0]})', \n",
        "             fontsize=14, fontweight='bold', y=0.995)\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save plot\n",
        "save_plot(fig_metrics, f\"MC_Dropout_metrics_mc_samples_comparison_{function_name}_{noise_type}\", \n",
        "          subfolder=f\"comparisons/{noise_type}/{func_type}\")\n",
        "plt.show()\n",
        "plt.close(fig_metrics)\n",
        "\n",
        "# Create metrics evolution plots vs epochs (grouped by mc_samples)\n",
        "fig_metrics_epochs, axes_metrics_epochs = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "for mc_val in unique_mc_samples:\n",
        "    mask = [ms == mc_val for ms in mc_samples_list]\n",
        "    epochs_subset = [epochs_list[i] for i in range(len(epochs_list)) if mask[i]]\n",
        "    nll_id_subset = [nll_id_list[i] for i in range(len(nll_id_list)) if mask[i]]\n",
        "    nll_ood_subset = [nll_ood_list[i] for i in range(len(nll_ood_list)) if mask[i]]\n",
        "    crps_id_subset = [crps_id_list[i] for i in range(len(crps_id_list)) if mask[i]]\n",
        "    crps_ood_subset = [crps_ood_list[i] for i in range(len(crps_ood_list)) if mask[i]]\n",
        "    spear_ale_id_subset = [spearman_aleatoric_id_list[i] for i in range(len(spearman_aleatoric_id_list)) if mask[i]]\n",
        "    spear_ale_ood_subset = [spearman_aleatoric_ood_list[i] for i in range(len(spearman_aleatoric_ood_list)) if mask[i]]\n",
        "    spear_epi_id_subset = [spearman_epistemic_id_list[i] for i in range(len(spearman_epistemic_id_list)) if mask[i]]\n",
        "    spear_epi_ood_subset = [spearman_epistemic_ood_list[i] for i in range(len(spearman_epistemic_ood_list)) if mask[i]]\n",
        "    \n",
        "    # Sort by epochs\n",
        "    sorted_epochs_idx = np.argsort(epochs_subset)\n",
        "    epochs_subset = [epochs_subset[i] for i in sorted_epochs_idx]\n",
        "    nll_id_subset = [nll_id_subset[i] for i in sorted_epochs_idx]\n",
        "    nll_ood_subset = [nll_ood_subset[i] for i in sorted_epochs_idx]\n",
        "    crps_id_subset = [crps_id_subset[i] for i in sorted_epochs_idx]\n",
        "    crps_ood_subset = [crps_ood_subset[i] for i in sorted_epochs_idx]\n",
        "    spear_ale_id_subset = [spear_ale_id_subset[i] for i in sorted_epochs_idx]\n",
        "    spear_ale_ood_subset = [spear_ale_ood_subset[i] for i in sorted_epochs_idx]\n",
        "    spear_epi_id_subset = [spear_epi_id_subset[i] for i in sorted_epochs_idx]\n",
        "    spear_epi_ood_subset = [spear_epi_ood_subset[i] for i in sorted_epochs_idx]\n",
        "    \n",
        "    # Plot NLL vs epochs\n",
        "    axes_metrics_epochs[0, 0].plot(epochs_subset, nll_id_subset, 'o-', label=f'NLL ID (M={mc_val})', linewidth=2, markersize=6)\n",
        "    axes_metrics_epochs[0, 0].plot(epochs_subset, nll_ood_subset, 's-', label=f'NLL OOD (M={mc_val})', linewidth=2, markersize=6)\n",
        "    \n",
        "    # Plot CRPS vs epochs\n",
        "    axes_metrics_epochs[0, 1].plot(epochs_subset, crps_id_subset, 'o-', label=f'CRPS ID (M={mc_val})', linewidth=2, markersize=6)\n",
        "    axes_metrics_epochs[0, 1].plot(epochs_subset, crps_ood_subset, 's-', label=f'CRPS OOD (M={mc_val})', linewidth=2, markersize=6)\n",
        "    \n",
        "    # Plot Spearman Aleatoric vs epochs\n",
        "    axes_metrics_epochs[1, 0].plot(epochs_subset, spear_ale_id_subset, 'o-', label=f'Spear Ale ID (M={mc_val})', linewidth=2, markersize=6)\n",
        "    axes_metrics_epochs[1, 0].plot(epochs_subset, spear_ale_ood_subset, 's-', label=f'Spear Ale OOD (M={mc_val})', linewidth=2, markersize=6)\n",
        "    \n",
        "    # Plot Spearman Epistemic vs epochs\n",
        "    axes_metrics_epochs[1, 1].plot(epochs_subset, spear_epi_id_subset, 'o-', label=f'Spear Epi ID (M={mc_val})', linewidth=2, markersize=6)\n",
        "    axes_metrics_epochs[1, 1].plot(epochs_subset, spear_epi_ood_subset, 's-', label=f'Spear Epi OOD (M={mc_val})', linewidth=2, markersize=6)\n",
        "\n",
        "axes_metrics_epochs[0, 0].set_xlabel('Epochs', fontsize=12)\n",
        "axes_metrics_epochs[0, 0].set_ylabel('NLL', fontsize=12)\n",
        "axes_metrics_epochs[0, 0].set_title(f'MC Dropout: NLL vs Epochs\\n{function_name} Function ({noise_type.capitalize()})', fontsize=13, fontweight='bold')\n",
        "axes_metrics_epochs[0, 0].legend(fontsize=9, ncol=2)\n",
        "axes_metrics_epochs[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "axes_metrics_epochs[0, 1].set_xlabel('Epochs', fontsize=12)\n",
        "axes_metrics_epochs[0, 1].set_ylabel('CRPS', fontsize=12)\n",
        "axes_metrics_epochs[0, 1].set_title(f'MC Dropout: CRPS vs Epochs\\n{function_name} Function ({noise_type.capitalize()})', fontsize=13, fontweight='bold')\n",
        "axes_metrics_epochs[0, 1].legend(fontsize=9, ncol=2)\n",
        "axes_metrics_epochs[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "axes_metrics_epochs[1, 0].set_xlabel('Epochs', fontsize=12)\n",
        "axes_metrics_epochs[1, 0].set_ylabel('Spearman Correlation', fontsize=12)\n",
        "axes_metrics_epochs[1, 0].set_title(f'MC Dropout: Spearman Aleatoric vs Epochs\\n{function_name} Function ({noise_type.capitalize()})', fontsize=13, fontweight='bold')\n",
        "axes_metrics_epochs[1, 0].legend(fontsize=9, ncol=2)\n",
        "axes_metrics_epochs[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "axes_metrics_epochs[1, 1].set_xlabel('Epochs', fontsize=12)\n",
        "axes_metrics_epochs[1, 1].set_ylabel('Spearman Correlation', fontsize=12)\n",
        "axes_metrics_epochs[1, 1].set_title(f'MC Dropout: Spearman Epistemic vs Epochs\\n{function_name} Function ({noise_type.capitalize()})', fontsize=13, fontweight='bold')\n",
        "axes_metrics_epochs[1, 1].legend(fontsize=9, ncol=2)\n",
        "axes_metrics_epochs[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.suptitle(f'MC Dropout Parameter Comparison: Metrics vs Epochs (p={dropout_p_values[0]})', \n",
        "             fontsize=14, fontweight='bold', y=0.995)\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save plot\n",
        "save_plot(fig_metrics_epochs, f\"MC_Dropout_metrics_epochs_comparison_{function_name}_{noise_type}\", \n",
        "          subfolder=f\"comparisons/{noise_type}/{func_type}\")\n",
        "plt.show()\n",
        "plt.close(fig_metrics_epochs)\n",
        "\n",
        "# Create summary table (for first epoch value and first p value to keep it manageable)\n",
        "# Use already filtered data\n",
        "comparison_df = pd.DataFrame({\n",
        "    'MC_Samples': [mc_samples_list[i] for i in range(len(mc_samples_list)) if mask_filtered[i]],\n",
        "    'Epochs': [epochs_list[i] for i in range(len(epochs_list)) if mask_filtered[i]],\n",
        "    'Dropout_p': [p_list[i] for i in range(len(p_list)) if mask_filtered[i]],\n",
        "    'Avg_Ale_ID': [avg_ale_id_list[i] for i in range(len(avg_ale_id_list)) if mask_filtered[i]],\n",
        "    'Avg_Epi_ID': [avg_epi_id_list[i] for i in range(len(avg_epi_id_list)) if mask_filtered[i]],\n",
        "    'Avg_Tot_ID': [avg_tot_id_list[i] for i in range(len(avg_tot_id_list)) if mask_filtered[i]],\n",
        "    'Avg_Ale_OOD': [avg_ale_ood_list[i] for i in range(len(avg_ale_ood_list)) if mask_filtered[i]],\n",
        "    'Avg_Epi_OOD': [avg_epi_ood_list[i] for i in range(len(avg_epi_ood_list)) if mask_filtered[i]],\n",
        "    'Avg_Tot_OOD': [avg_tot_ood_list[i] for i in range(len(avg_tot_ood_list)) if mask_filtered[i]],\n",
        "    'Avg_Ale_Entropy_ID': [avg_ale_entropy_id_list[i] for i in range(len(avg_ale_entropy_id_list)) if mask_filtered[i]],\n",
        "    'Avg_Epi_Entropy_ID': [avg_epi_entropy_id_list[i] for i in range(len(avg_epi_entropy_id_list)) if mask_filtered[i]],\n",
        "    'Avg_Tot_Entropy_ID': [avg_tot_entropy_id_list[i] for i in range(len(avg_tot_entropy_id_list)) if mask_filtered[i]],\n",
        "    'Avg_Ale_Entropy_OOD': [avg_ale_entropy_ood_list[i] for i in range(len(avg_ale_entropy_ood_list)) if mask_filtered[i]],\n",
        "    'Avg_Epi_Entropy_OOD': [avg_epi_entropy_ood_list[i] for i in range(len(avg_epi_entropy_ood_list)) if mask_filtered[i]],\n",
        "    'Avg_Tot_Entropy_OOD': [avg_tot_entropy_ood_list[i] for i in range(len(avg_tot_entropy_ood_list)) if mask_filtered[i]],\n",
        "    'MSE_ID': [mse_id_list[i] for i in range(len(mse_id_list)) if mask_filtered[i]],\n",
        "    'MSE_OOD': [mse_ood_list[i] for i in range(len(mse_ood_list)) if mask_filtered[i]],\n",
        "    'NLL_ID': [nll_id_list[i] for i in range(len(nll_id_list)) if mask_filtered[i]],\n",
        "    'NLL_OOD': [nll_ood_list[i] for i in range(len(nll_ood_list)) if mask_filtered[i]],\n",
        "    'CRPS_ID': [crps_id_list[i] for i in range(len(crps_id_list)) if mask_filtered[i]],\n",
        "    'CRPS_OOD': [crps_ood_list[i] for i in range(len(crps_ood_list)) if mask_filtered[i]],\n",
        "    'Spear_Ale_ID': [spearman_aleatoric_id_list[i] for i in range(len(spearman_aleatoric_id_list)) if mask_filtered[i]],\n",
        "    'Spear_Ale_OOD': [spearman_aleatoric_ood_list[i] for i in range(len(spearman_aleatoric_ood_list)) if mask_filtered[i]],\n",
        "    'Spear_Epi_ID': [spearman_epistemic_id_list[i] for i in range(len(spearman_epistemic_id_list)) if mask_filtered[i]],\n",
        "    'Spear_Epi_OOD': [spearman_epistemic_ood_list[i] for i in range(len(spearman_epistemic_ood_list)) if mask_filtered[i]]\n",
        "})\n",
        "\n",
        "print(\"\\nSummary Table:\")\n",
        "print(comparison_df.to_string(index=False))\n",
        "\n",
        "# Save comparison table\n",
        "save_statistics(comparison_df, f\"MC_Dropout_mc_samples_comparison_{function_name}_{noise_type}\",\n",
        "                subfolder=f\"comparisons/{noise_type}/{func_type}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Deep Ensemble - Vary K\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Store results for comparison\n",
        "results_deep_ensemble = {}\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(f\"Deep Ensemble Parameter Comparison - Varying K and epochs\")\n",
        "print(f\"{'='*80}\\n\")\n",
        "\n",
        "for K in K_values:\n",
        "    for epochs_val in epochs_values:\n",
        "        param_key = f\"K{K}_E{epochs_val}\"\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Testing: K={K}, epochs={epochs_val}\")\n",
        "        print(f\"{'='*60}\")\n",
        "        \n",
        "        result = run_single_deep_ensemble_ood(\n",
        "            generate_toy_regression, x_train, y_train, x_grid, y_grid_clean, ood_mask,\n",
        "            K=K, beta=beta, batch_size=batch_size, epochs=epochs_val, seed=seed,\n",
        "            function_name=function_name, noise_type=noise_type, func_type=func_type,\n",
        "            date=date, save_results=True\n",
        "        )\n",
        "        \n",
        "        results_deep_ensemble[param_key] = result\n",
        "        \n",
        "        # Print summary\n",
        "        print(f\"  ID - Avg Ale: {np.mean(result['uncertainties_id']['ale']):.6f}, \"\n",
        "              f\"Avg Epi: {np.mean(result['uncertainties_id']['epi']):.6f}, \"\n",
        "              f\"MSE: {result['mse_id']:.6f}\")\n",
        "        print(f\"  OOD - Avg Ale: {np.mean(result['uncertainties_ood']['ale']):.6f}, \"\n",
        "              f\"Avg Epi: {np.mean(result['uncertainties_ood']['epi']):.6f}, \"\n",
        "              f\"MSE: {result['mse_ood']:.6f}\")\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"Deep Ensemble experiments completed!\")\n",
        "print(f\"{'='*80}\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Deep Ensemble - Comparison Plots\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract data for plotting\n",
        "K_list = []\n",
        "epochs_list_de = []\n",
        "avg_ale_id_list_de = []\n",
        "avg_epi_id_list_de = []\n",
        "avg_tot_id_list_de = []\n",
        "avg_ale_ood_list_de = []\n",
        "avg_epi_ood_list_de = []\n",
        "avg_tot_ood_list_de = []\n",
        "avg_ale_entropy_id_list_de = []\n",
        "avg_epi_entropy_id_list_de = []\n",
        "avg_tot_entropy_id_list_de = []\n",
        "avg_ale_entropy_ood_list_de = []\n",
        "avg_epi_entropy_ood_list_de = []\n",
        "avg_tot_entropy_ood_list_de = []\n",
        "mse_id_list_de = []\n",
        "mse_ood_list_de = []\n",
        "nll_id_list_de = []\n",
        "nll_ood_list_de = []\n",
        "crps_id_list_de = []\n",
        "crps_ood_list_de = []\n",
        "spearman_aleatoric_id_list_de = []\n",
        "spearman_aleatoric_ood_list_de = []\n",
        "spearman_epistemic_id_list_de = []\n",
        "spearman_epistemic_ood_list_de = []\n",
        "\n",
        "for param_key, result in results_deep_ensemble.items():\n",
        "    # Extract K and epochs from param_key (format: \"K5_E250\")\n",
        "    parts = param_key.split('_')\n",
        "    K_val = int(parts[0][1:])  # Extract number after 'K'\n",
        "    epochs_val = int(parts[1][1:])  # Extract number after 'E'\n",
        "    K_list.append(K_val)\n",
        "    epochs_list_de.append(epochs_val)\n",
        "    \n",
        "    avg_ale_id_list_de.append(np.mean(result['uncertainties_id']['ale']))\n",
        "    avg_epi_id_list_de.append(np.mean(result['uncertainties_id']['epi']))\n",
        "    avg_tot_id_list_de.append(np.mean(result['uncertainties_id']['tot']))\n",
        "    \n",
        "    avg_ale_ood_list_de.append(np.mean(result['uncertainties_ood']['ale']))\n",
        "    avg_epi_ood_list_de.append(np.mean(result['uncertainties_ood']['epi']))\n",
        "    avg_tot_ood_list_de.append(np.mean(result['uncertainties_ood']['tot']))\n",
        "    \n",
        "    # Extract entropy-based uncertainties\n",
        "    avg_ale_entropy_id_list_de.append(np.mean(result['uncertainties_entropy_id']['ale']))\n",
        "    avg_epi_entropy_id_list_de.append(np.mean(result['uncertainties_entropy_id']['epi']))\n",
        "    avg_tot_entropy_id_list_de.append(np.mean(result['uncertainties_entropy_id']['tot']))\n",
        "    \n",
        "    avg_ale_entropy_ood_list_de.append(np.mean(result['uncertainties_entropy_ood']['ale']))\n",
        "    avg_epi_entropy_ood_list_de.append(np.mean(result['uncertainties_entropy_ood']['epi']))\n",
        "    avg_tot_entropy_ood_list_de.append(np.mean(result['uncertainties_entropy_ood']['tot']))\n",
        "    \n",
        "    mse_id_list_de.append(result['mse_id'])\n",
        "    mse_ood_list_de.append(result['mse_ood'])\n",
        "    nll_id_list_de.append(result['nll_id'])\n",
        "    nll_ood_list_de.append(result['nll_ood'])\n",
        "    crps_id_list_de.append(result['crps_id'])\n",
        "    crps_ood_list_de.append(result['crps_ood'])\n",
        "    spearman_aleatoric_id_list_de.append(result['spearman_aleatoric_id'])\n",
        "    spearman_aleatoric_ood_list_de.append(result['spearman_aleatoric_ood'])\n",
        "    spearman_epistemic_id_list_de.append(result['spearman_epistemic_id'])\n",
        "    spearman_epistemic_ood_list_de.append(result['spearman_epistemic_ood'])\n",
        "\n",
        "# Sort by K first, then by epochs\n",
        "sorted_indices = np.lexsort((epochs_list_de, K_list))\n",
        "K_list = [K_list[i] for i in sorted_indices]\n",
        "epochs_list_de = [epochs_list_de[i] for i in sorted_indices]\n",
        "avg_ale_id_list_de = [avg_ale_id_list_de[i] for i in sorted_indices]\n",
        "avg_epi_id_list_de = [avg_epi_id_list_de[i] for i in sorted_indices]\n",
        "avg_tot_id_list_de = [avg_tot_id_list_de[i] for i in sorted_indices]\n",
        "avg_ale_ood_list_de = [avg_ale_ood_list_de[i] for i in sorted_indices]\n",
        "avg_epi_ood_list_de = [avg_epi_ood_list_de[i] for i in sorted_indices]\n",
        "avg_tot_ood_list_de = [avg_tot_ood_list_de[i] for i in sorted_indices]\n",
        "avg_ale_entropy_id_list_de = [avg_ale_entropy_id_list_de[i] for i in sorted_indices]\n",
        "avg_epi_entropy_id_list_de = [avg_epi_entropy_id_list_de[i] for i in sorted_indices]\n",
        "avg_tot_entropy_id_list_de = [avg_tot_entropy_id_list_de[i] for i in sorted_indices]\n",
        "avg_ale_entropy_ood_list_de = [avg_ale_entropy_ood_list_de[i] for i in sorted_indices]\n",
        "avg_epi_entropy_ood_list_de = [avg_epi_entropy_ood_list_de[i] for i in sorted_indices]\n",
        "avg_tot_entropy_ood_list_de = [avg_tot_entropy_ood_list_de[i] for i in sorted_indices]\n",
        "mse_id_list_de = [mse_id_list_de[i] for i in sorted_indices]\n",
        "mse_ood_list_de = [mse_ood_list_de[i] for i in sorted_indices]\n",
        "nll_id_list_de = [nll_id_list_de[i] for i in sorted_indices]\n",
        "nll_ood_list_de = [nll_ood_list_de[i] for i in sorted_indices]\n",
        "crps_id_list_de = [crps_id_list_de[i] for i in sorted_indices]\n",
        "crps_ood_list_de = [crps_ood_list_de[i] for i in sorted_indices]\n",
        "spearman_aleatoric_id_list_de = [spearman_aleatoric_id_list_de[i] for i in sorted_indices]\n",
        "spearman_aleatoric_ood_list_de = [spearman_aleatoric_ood_list_de[i] for i in sorted_indices]\n",
        "spearman_epistemic_id_list_de = [spearman_epistemic_id_list_de[i] for i in sorted_indices]\n",
        "spearman_epistemic_ood_list_de = [spearman_epistemic_ood_list_de[i] for i in sorted_indices]\n",
        "\n",
        "# Filter for first epoch value for K plots (to avoid multiple points per K)\n",
        "first_epoch = epochs_values[0]\n",
        "mask_first_epoch_de = [e == first_epoch for e in epochs_list_de]\n",
        "K_filtered = [K_list[i] for i in range(len(K_list)) if mask_first_epoch_de[i]]\n",
        "avg_ale_id_filtered_de = [avg_ale_id_list_de[i] for i in range(len(avg_ale_id_list_de)) if mask_first_epoch_de[i]]\n",
        "avg_epi_id_filtered_de = [avg_epi_id_list_de[i] for i in range(len(avg_epi_id_list_de)) if mask_first_epoch_de[i]]\n",
        "avg_tot_id_filtered_de = [avg_tot_id_list_de[i] for i in range(len(avg_tot_id_list_de)) if mask_first_epoch_de[i]]\n",
        "avg_ale_ood_filtered_de = [avg_ale_ood_list_de[i] for i in range(len(avg_ale_ood_list_de)) if mask_first_epoch_de[i]]\n",
        "avg_epi_ood_filtered_de = [avg_epi_ood_list_de[i] for i in range(len(avg_epi_ood_list_de)) if mask_first_epoch_de[i]]\n",
        "avg_tot_ood_filtered_de = [avg_tot_ood_list_de[i] for i in range(len(avg_tot_ood_list_de)) if mask_first_epoch_de[i]]\n",
        "avg_ale_entropy_id_filtered_de = [avg_ale_entropy_id_list_de[i] for i in range(len(avg_ale_entropy_id_list_de)) if mask_first_epoch_de[i]]\n",
        "avg_epi_entropy_id_filtered_de = [avg_epi_entropy_id_list_de[i] for i in range(len(avg_epi_entropy_id_list_de)) if mask_first_epoch_de[i]]\n",
        "avg_tot_entropy_id_filtered_de = [avg_tot_entropy_id_list_de[i] for i in range(len(avg_tot_entropy_id_list_de)) if mask_first_epoch_de[i]]\n",
        "avg_ale_entropy_ood_filtered_de = [avg_ale_entropy_ood_list_de[i] for i in range(len(avg_ale_entropy_ood_list_de)) if mask_first_epoch_de[i]]\n",
        "avg_epi_entropy_ood_filtered_de = [avg_epi_entropy_ood_list_de[i] for i in range(len(avg_epi_entropy_ood_list_de)) if mask_first_epoch_de[i]]\n",
        "avg_tot_entropy_ood_filtered_de = [avg_tot_entropy_ood_list_de[i] for i in range(len(avg_tot_entropy_ood_list_de)) if mask_first_epoch_de[i]]\n",
        "mse_id_filtered_de = [mse_id_list_de[i] for i in range(len(mse_id_list_de)) if mask_first_epoch_de[i]]\n",
        "mse_ood_filtered_de = [mse_ood_list_de[i] for i in range(len(mse_ood_list_de)) if mask_first_epoch_de[i]]\n",
        "nll_id_filtered_de = [nll_id_list_de[i] for i in range(len(nll_id_list_de)) if mask_first_epoch_de[i]]\n",
        "nll_ood_filtered_de = [nll_ood_list_de[i] for i in range(len(nll_ood_list_de)) if mask_first_epoch_de[i]]\n",
        "crps_id_filtered_de = [crps_id_list_de[i] for i in range(len(crps_id_list_de)) if mask_first_epoch_de[i]]\n",
        "crps_ood_filtered_de = [crps_ood_list_de[i] for i in range(len(crps_ood_list_de)) if mask_first_epoch_de[i]]\n",
        "spearman_aleatoric_id_filtered_de = [spearman_aleatoric_id_list_de[i] for i in range(len(spearman_aleatoric_id_list_de)) if mask_first_epoch_de[i]]\n",
        "spearman_aleatoric_ood_filtered_de = [spearman_aleatoric_ood_list_de[i] for i in range(len(spearman_aleatoric_ood_list_de)) if mask_first_epoch_de[i]]\n",
        "spearman_epistemic_id_filtered_de = [spearman_epistemic_id_list_de[i] for i in range(len(spearman_epistemic_id_list_de)) if mask_first_epoch_de[i]]\n",
        "spearman_epistemic_ood_filtered_de = [spearman_epistemic_ood_list_de[i] for i in range(len(spearman_epistemic_ood_list_de)) if mask_first_epoch_de[i]]\n",
        "avg_epi_id_filtered_plot_de = [avg_epi_id_list_de[i] for i in range(len(avg_epi_id_list_de)) if mask_first_epoch_de[i]]\n",
        "avg_epi_ood_filtered_plot_de = [avg_epi_ood_list_de[i] for i in range(len(avg_epi_ood_list_de)) if mask_first_epoch_de[i]]\n",
        "\n",
        "# Create comparison plots\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "# Plot 1: Average Uncertainties - ID region\n",
        "axes[0, 0].plot(K_filtered, avg_ale_id_filtered_de, 'o-', label='Aleatoric (ID)', color='green', linewidth=2, markersize=8)\n",
        "axes[0, 0].plot(K_filtered, avg_epi_id_filtered_de, 's-', label='Epistemic (ID)', color='orange', linewidth=2, markersize=8)\n",
        "axes[0, 0].plot(K_filtered, avg_tot_id_filtered_de, '^-', label='Total (ID)', color='blue', linewidth=2, markersize=8)\n",
        "axes[0, 0].set_xlabel('Number of Nets (K)', fontsize=12)\n",
        "axes[0, 0].set_ylabel('Average Uncertainty', fontsize=12)\n",
        "axes[0, 0].set_title(f'Deep Ensemble: Average Uncertainties (ID) vs K\\n{function_name} Function ({noise_type.capitalize()})', fontsize=13, fontweight='bold')\n",
        "axes[0, 0].legend(fontsize=10)\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "axes[0, 0].set_xticks(K_filtered)\n",
        "\n",
        "# Plot 2: Average Entropy Uncertainties - ID region\n",
        "axes[0, 1].plot(K_filtered, avg_ale_entropy_id_filtered_de, 'o-', label='Aleatoric Entropy (ID)', color='green', linewidth=2, markersize=8)\n",
        "axes[0, 1].plot(K_filtered, avg_epi_entropy_id_filtered_de, 's-', label='Epistemic Entropy (ID)', color='orange', linewidth=2, markersize=8)\n",
        "axes[0, 1].plot(K_filtered, avg_tot_entropy_id_filtered_de, '^-', label='Total Entropy (ID)', color='blue', linewidth=2, markersize=8)\n",
        "axes[0, 1].set_xlabel('Number of Nets (K)', fontsize=12)\n",
        "axes[0, 1].set_ylabel('Average Entropy Uncertainty', fontsize=12)\n",
        "axes[0, 1].set_title(f'Deep Ensemble: Average Entropy Uncertainties (ID) vs K\\n{function_name} Function ({noise_type.capitalize()})', fontsize=13, fontweight='bold')\n",
        "axes[0, 1].legend(fontsize=10)\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "axes[0, 1].set_xticks(K_filtered)\n",
        "\n",
        "# Plot 3: MSE comparison\n",
        "axes[1, 0].plot(K_filtered, mse_id_filtered_de, 'o-', label='MSE (ID)', color='blue', linewidth=2, markersize=8)\n",
        "axes[1, 0].plot(K_filtered, mse_ood_filtered_de, 's-', label='MSE (OOD)', color='red', linewidth=2, markersize=8)\n",
        "axes[1, 0].set_xlabel('Number of Nets (K)', fontsize=12)\n",
        "axes[1, 0].set_ylabel('MSE', fontsize=12)\n",
        "axes[1, 0].set_title(f'Deep Ensemble: MSE vs K\\n{function_name} Function ({noise_type.capitalize()})', fontsize=13, fontweight='bold')\n",
        "axes[1, 0].legend(fontsize=10)\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "axes[1, 0].set_yscale('log')\n",
        "axes[1, 0].set_xticks(K_filtered)\n",
        "\n",
        "# Plot 4: ID vs OOD comparison (bar chart)\n",
        "x_pos = np.arange(len(K_filtered))\n",
        "width = 0.35\n",
        "axes[1, 1].bar(x_pos - width/2, avg_epi_id_filtered_plot_de, width, label='Epistemic (ID)', color='orange', alpha=0.7)\n",
        "axes[1, 1].bar(x_pos + width/2, avg_epi_ood_filtered_plot_de, width, label='Epistemic (OOD)', color='red', alpha=0.7)\n",
        "axes[1, 1].set_xlabel('Number of Nets (K)', fontsize=12)\n",
        "axes[1, 1].set_ylabel('Average Epistemic Uncertainty', fontsize=12)\n",
        "axes[1, 1].set_title(f'Deep Ensemble: Epistemic Uncertainty - ID vs OOD\\n{function_name} Function ({noise_type.capitalize()})', fontsize=13, fontweight='bold')\n",
        "axes[1, 1].set_xticks(x_pos)\n",
        "axes[1, 1].set_xticklabels(K_filtered)\n",
        "axes[1, 1].legend(fontsize=10)\n",
        "axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "plt.suptitle(f'Deep Ensemble Parameter Comparison: Varying K (epochs={epochs_values[0]})', \n",
        "             fontsize=14, fontweight='bold', y=0.995)\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save plot\n",
        "save_plot(fig, f\"Deep_Ensemble_K_comparison_{function_name}_{noise_type}\", \n",
        "          subfolder=f\"comparisons/{noise_type}/{func_type}\")\n",
        "plt.show()\n",
        "plt.close(fig)\n",
        "\n",
        "# Create plots showing epochs variation (for fixed K)\n",
        "# Group by K and plot epochs variation\n",
        "unique_K = sorted(set(K_list))\n",
        "fig_epochs_de, axes_epochs_de = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "for K_val in unique_K:\n",
        "    # Filter data for this K value\n",
        "    mask = [k == K_val for k in K_list]\n",
        "    epochs_subset = [epochs_list_de[i] for i in range(len(epochs_list_de)) if mask[i]]\n",
        "    ale_id_subset = [avg_ale_id_list_de[i] for i in range(len(avg_ale_id_list_de)) if mask[i]]\n",
        "    epi_id_subset = [avg_epi_id_list_de[i] for i in range(len(avg_epi_id_list_de)) if mask[i]]\n",
        "    tot_id_subset = [avg_tot_id_list_de[i] for i in range(len(avg_tot_id_list_de)) if mask[i]]\n",
        "    ale_entropy_id_subset = [avg_ale_entropy_id_list_de[i] for i in range(len(avg_ale_entropy_id_list_de)) if mask[i]]\n",
        "    epi_entropy_id_subset = [avg_epi_entropy_id_list_de[i] for i in range(len(avg_epi_entropy_id_list_de)) if mask[i]]\n",
        "    tot_entropy_id_subset = [avg_tot_entropy_id_list_de[i] for i in range(len(avg_tot_entropy_id_list_de)) if mask[i]]\n",
        "    ale_ood_subset = [avg_ale_ood_list_de[i] for i in range(len(avg_ale_ood_list_de)) if mask[i]]\n",
        "    epi_ood_subset = [avg_epi_ood_list_de[i] for i in range(len(avg_epi_ood_list_de)) if mask[i]]\n",
        "    tot_ood_subset = [avg_tot_ood_list_de[i] for i in range(len(avg_tot_ood_list_de)) if mask[i]]\n",
        "    mse_id_subset = [mse_id_list_de[i] for i in range(len(mse_id_list_de)) if mask[i]]\n",
        "    mse_ood_subset = [mse_ood_list_de[i] for i in range(len(mse_ood_list_de)) if mask[i]]\n",
        "    \n",
        "    # Sort by epochs\n",
        "    sorted_epochs_idx = np.argsort(epochs_subset)\n",
        "    epochs_subset = [epochs_subset[i] for i in sorted_epochs_idx]\n",
        "    ale_id_subset = [ale_id_subset[i] for i in sorted_epochs_idx]\n",
        "    epi_id_subset = [epi_id_subset[i] for i in sorted_epochs_idx]\n",
        "    tot_id_subset = [tot_id_subset[i] for i in sorted_epochs_idx]\n",
        "    ale_entropy_id_subset = [ale_entropy_id_subset[i] for i in sorted_epochs_idx]\n",
        "    epi_entropy_id_subset = [epi_entropy_id_subset[i] for i in sorted_epochs_idx]\n",
        "    tot_entropy_id_subset = [tot_entropy_id_subset[i] for i in sorted_epochs_idx]\n",
        "    ale_ood_subset = [ale_ood_subset[i] for i in sorted_epochs_idx]\n",
        "    epi_ood_subset = [epi_ood_subset[i] for i in sorted_epochs_idx]\n",
        "    tot_ood_subset = [tot_ood_subset[i] for i in sorted_epochs_idx]\n",
        "    mse_id_subset = [mse_id_subset[i] for i in sorted_epochs_idx]\n",
        "    mse_ood_subset = [mse_ood_subset[i] for i in sorted_epochs_idx]\n",
        "    \n",
        "    # Plot ID uncertainties vs epochs\n",
        "    axes_epochs_de[0, 0].plot(epochs_subset, ale_id_subset, 'o-', label=f'Aleatoric (K={K_val})', linewidth=2, markersize=6)\n",
        "    axes_epochs_de[0, 0].plot(epochs_subset, epi_id_subset, 's-', label=f'Epistemic (K={K_val})', linewidth=2, markersize=6)\n",
        "    \n",
        "    # Plot ID entropy uncertainties vs epochs\n",
        "    axes_epochs_de[0, 1].plot(epochs_subset, ale_entropy_id_subset, 'o-', label=f'Aleatoric Entropy (K={K_val})', linewidth=2, markersize=6)\n",
        "    axes_epochs_de[0, 1].plot(epochs_subset, epi_entropy_id_subset, 's-', label=f'Epistemic Entropy (K={K_val})', linewidth=2, markersize=6)\n",
        "    \n",
        "    # Plot MSE vs epochs\n",
        "    axes_epochs_de[1, 0].plot(epochs_subset, mse_id_subset, 'o-', label=f'MSE ID (K={K_val})', linewidth=2, markersize=6)\n",
        "    axes_epochs_de[1, 0].plot(epochs_subset, mse_ood_subset, 's-', label=f'MSE OOD (K={K_val})', linewidth=2, markersize=6)\n",
        "\n",
        "axes_epochs_de[0, 0].set_xlabel('Epochs', fontsize=12)\n",
        "axes_epochs_de[0, 0].set_ylabel('Average Uncertainty', fontsize=12)\n",
        "axes_epochs_de[0, 0].set_title(f'Deep Ensemble: Average Uncertainties (ID) vs Epochs\\n{function_name} Function ({noise_type.capitalize()})', fontsize=13, fontweight='bold')\n",
        "axes_epochs_de[0, 0].legend(fontsize=9, ncol=2)\n",
        "axes_epochs_de[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "axes_epochs_de[0, 1].set_xlabel('Epochs', fontsize=12)\n",
        "axes_epochs_de[0, 1].set_ylabel('Average Entropy Uncertainty', fontsize=12)\n",
        "axes_epochs_de[0, 1].set_title(f'Deep Ensemble: Average Entropy Uncertainties (ID) vs Epochs\\n{function_name} Function ({noise_type.capitalize()})', fontsize=13, fontweight='bold')\n",
        "axes_epochs_de[0, 1].legend(fontsize=9, ncol=2)\n",
        "axes_epochs_de[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "axes_epochs_de[1, 0].set_xlabel('Epochs', fontsize=12)\n",
        "axes_epochs_de[1, 0].set_ylabel('MSE', fontsize=12)\n",
        "axes_epochs_de[1, 0].set_title(f'Deep Ensemble: MSE vs Epochs\\n{function_name} Function ({noise_type.capitalize()})', fontsize=13, fontweight='bold')\n",
        "axes_epochs_de[1, 0].legend(fontsize=9, ncol=2)\n",
        "axes_epochs_de[1, 0].grid(True, alpha=0.3)\n",
        "axes_epochs_de[1, 0].set_yscale('log')\n",
        "\n",
        "# Plot comparison of epistemic uncertainty ID vs OOD for different epochs\n",
        "for K_val in unique_K:\n",
        "    mask = [k == K_val for k in K_list]\n",
        "    epochs_subset = [epochs_list_de[i] for i in range(len(epochs_list_de)) if mask[i]]\n",
        "    epi_id_subset = [avg_epi_id_list_de[i] for i in range(len(avg_epi_id_list_de)) if mask[i]]\n",
        "    epi_ood_subset = [avg_epi_ood_list_de[i] for i in range(len(avg_epi_ood_list_de)) if mask[i]]\n",
        "    sorted_epochs_idx = np.argsort(epochs_subset)\n",
        "    epochs_subset = [epochs_subset[i] for i in sorted_epochs_idx]\n",
        "    epi_id_subset = [epi_id_subset[i] for i in sorted_epochs_idx]\n",
        "    epi_ood_subset = [epi_ood_subset[i] for i in sorted_epochs_idx]\n",
        "    axes_epochs_de[1, 1].plot(epochs_subset, epi_id_subset, 'o-', label=f'Epistemic ID (K={K_val})', linewidth=2, markersize=6)\n",
        "    axes_epochs_de[1, 1].plot(epochs_subset, epi_ood_subset, 's--', label=f'Epistemic OOD (K={K_val})', linewidth=2, markersize=6)\n",
        "\n",
        "axes_epochs_de[1, 1].set_xlabel('Epochs', fontsize=12)\n",
        "axes_epochs_de[1, 1].set_ylabel('Average Epistemic Uncertainty', fontsize=12)\n",
        "axes_epochs_de[1, 1].set_title(f'Deep Ensemble: Epistemic Uncertainty - ID vs OOD\\n{function_name} Function ({noise_type.capitalize()})', fontsize=13, fontweight='bold')\n",
        "axes_epochs_de[1, 1].legend(fontsize=9, ncol=2)\n",
        "axes_epochs_de[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.suptitle(f'Deep Ensemble Parameter Comparison: Varying Epochs', \n",
        "             fontsize=14, fontweight='bold', y=0.995)\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save plot\n",
        "save_plot(fig_epochs_de, f\"Deep_Ensemble_epochs_comparison_{function_name}_{noise_type}\", \n",
        "          subfolder=f\"comparisons/{noise_type}/{func_type}\")\n",
        "plt.show()\n",
        "plt.close(fig_epochs_de)\n",
        "\n",
        "# Create metrics evolution plots (NLL, CRPS, Spearman) vs K\n",
        "fig_metrics_de, axes_metrics_de = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "# Plot 1: NLL vs K\n",
        "axes_metrics_de[0, 0].plot(K_filtered, nll_id_filtered_de, 'o-', label='NLL (ID)', color='blue', linewidth=2, markersize=8)\n",
        "axes_metrics_de[0, 0].plot(K_filtered, nll_ood_filtered_de, 's-', label='NLL (OOD)', color='red', linewidth=2, markersize=8)\n",
        "axes_metrics_de[0, 0].set_xlabel('Number of Nets (K)', fontsize=12)\n",
        "axes_metrics_de[0, 0].set_ylabel('NLL', fontsize=12)\n",
        "axes_metrics_de[0, 0].set_title(f'Deep Ensemble: NLL vs K\\n{function_name} Function ({noise_type.capitalize()})', fontsize=13, fontweight='bold')\n",
        "axes_metrics_de[0, 0].legend(fontsize=10)\n",
        "axes_metrics_de[0, 0].grid(True, alpha=0.3)\n",
        "axes_metrics_de[0, 0].set_xticks(K_filtered)\n",
        "\n",
        "# Plot 2: CRPS vs K\n",
        "axes_metrics_de[0, 1].plot(K_filtered, crps_id_filtered_de, 'o-', label='CRPS (ID)', color='blue', linewidth=2, markersize=8)\n",
        "axes_metrics_de[0, 1].plot(K_filtered, crps_ood_filtered_de, 's-', label='CRPS (OOD)', color='red', linewidth=2, markersize=8)\n",
        "axes_metrics_de[0, 1].set_xlabel('Number of Nets (K)', fontsize=12)\n",
        "axes_metrics_de[0, 1].set_ylabel('CRPS', fontsize=12)\n",
        "axes_metrics_de[0, 1].set_title(f'Deep Ensemble: CRPS vs K\\n{function_name} Function ({noise_type.capitalize()})', fontsize=13, fontweight='bold')\n",
        "axes_metrics_de[0, 1].legend(fontsize=10)\n",
        "axes_metrics_de[0, 1].grid(True, alpha=0.3)\n",
        "axes_metrics_de[0, 1].set_xticks(K_filtered)\n",
        "\n",
        "# Plot 3: Spearman Aleatoric vs K\n",
        "axes_metrics_de[1, 0].plot(K_filtered, spearman_aleatoric_id_filtered_de, 'o-', label='Spearman Aleatoric (ID)', color='green', linewidth=2, markersize=8)\n",
        "axes_metrics_de[1, 0].plot(K_filtered, spearman_aleatoric_ood_filtered_de, 's-', label='Spearman Aleatoric (OOD)', color='darkgreen', linewidth=2, markersize=8)\n",
        "axes_metrics_de[1, 0].set_xlabel('Number of Nets (K)', fontsize=12)\n",
        "axes_metrics_de[1, 0].set_ylabel('Spearman Correlation', fontsize=12)\n",
        "axes_metrics_de[1, 0].set_title(f'Deep Ensemble: Spearman Aleatoric vs K\\n{function_name} Function ({noise_type.capitalize()})', fontsize=13, fontweight='bold')\n",
        "axes_metrics_de[1, 0].legend(fontsize=10)\n",
        "axes_metrics_de[1, 0].grid(True, alpha=0.3)\n",
        "axes_metrics_de[1, 0].set_xticks(K_filtered)\n",
        "\n",
        "# Plot 4: Spearman Epistemic vs K\n",
        "axes_metrics_de[1, 1].plot(K_filtered, spearman_epistemic_id_filtered_de, 'o-', label='Spearman Epistemic (ID)', color='orange', linewidth=2, markersize=8)\n",
        "axes_metrics_de[1, 1].plot(K_filtered, spearman_epistemic_ood_filtered_de, 's-', label='Spearman Epistemic (OOD)', color='red', linewidth=2, markersize=8)\n",
        "axes_metrics_de[1, 1].set_xlabel('Number of Nets (K)', fontsize=12)\n",
        "axes_metrics_de[1, 1].set_ylabel('Spearman Correlation', fontsize=12)\n",
        "axes_metrics_de[1, 1].set_title(f'Deep Ensemble: Spearman Epistemic vs K\\n{function_name} Function ({noise_type.capitalize()})', fontsize=13, fontweight='bold')\n",
        "axes_metrics_de[1, 1].legend(fontsize=10)\n",
        "axes_metrics_de[1, 1].grid(True, alpha=0.3)\n",
        "axes_metrics_de[1, 1].set_xticks(K_filtered)\n",
        "\n",
        "plt.suptitle(f'Deep Ensemble Parameter Comparison: Metrics vs K (epochs={epochs_values[0]})', \n",
        "             fontsize=14, fontweight='bold', y=0.995)\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save plot\n",
        "save_plot(fig_metrics_de, f\"Deep_Ensemble_metrics_K_comparison_{function_name}_{noise_type}\", \n",
        "          subfolder=f\"comparisons/{noise_type}/{func_type}\")\n",
        "plt.show()\n",
        "plt.close(fig_metrics_de)\n",
        "\n",
        "# Create metrics evolution plots vs epochs (grouped by K)\n",
        "fig_metrics_epochs_de, axes_metrics_epochs_de = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "for K_val in unique_K:\n",
        "    mask = [k == K_val for k in K_list]\n",
        "    epochs_subset = [epochs_list_de[i] for i in range(len(epochs_list_de)) if mask[i]]\n",
        "    nll_id_subset = [nll_id_list_de[i] for i in range(len(nll_id_list_de)) if mask[i]]\n",
        "    nll_ood_subset = [nll_ood_list_de[i] for i in range(len(nll_ood_list_de)) if mask[i]]\n",
        "    crps_id_subset = [crps_id_list_de[i] for i in range(len(crps_id_list_de)) if mask[i]]\n",
        "    crps_ood_subset = [crps_ood_list_de[i] for i in range(len(crps_ood_list_de)) if mask[i]]\n",
        "    spear_ale_id_subset = [spearman_aleatoric_id_list_de[i] for i in range(len(spearman_aleatoric_id_list_de)) if mask[i]]\n",
        "    spear_ale_ood_subset = [spearman_aleatoric_ood_list_de[i] for i in range(len(spearman_aleatoric_ood_list_de)) if mask[i]]\n",
        "    spear_epi_id_subset = [spearman_epistemic_id_list_de[i] for i in range(len(spearman_epistemic_id_list_de)) if mask[i]]\n",
        "    spear_epi_ood_subset = [spearman_epistemic_ood_list_de[i] for i in range(len(spearman_epistemic_ood_list_de)) if mask[i]]\n",
        "    \n",
        "    # Sort by epochs\n",
        "    sorted_epochs_idx = np.argsort(epochs_subset)\n",
        "    epochs_subset = [epochs_subset[i] for i in sorted_epochs_idx]\n",
        "    nll_id_subset = [nll_id_subset[i] for i in sorted_epochs_idx]\n",
        "    nll_ood_subset = [nll_ood_subset[i] for i in sorted_epochs_idx]\n",
        "    crps_id_subset = [crps_id_subset[i] for i in sorted_epochs_idx]\n",
        "    crps_ood_subset = [crps_ood_subset[i] for i in sorted_epochs_idx]\n",
        "    spear_ale_id_subset = [spear_ale_id_subset[i] for i in sorted_epochs_idx]\n",
        "    spear_ale_ood_subset = [spear_ale_ood_subset[i] for i in sorted_epochs_idx]\n",
        "    spear_epi_id_subset = [spear_epi_id_subset[i] for i in sorted_epochs_idx]\n",
        "    spear_epi_ood_subset = [spear_epi_ood_subset[i] for i in sorted_epochs_idx]\n",
        "    \n",
        "    # Plot NLL vs epochs\n",
        "    axes_metrics_epochs_de[0, 0].plot(epochs_subset, nll_id_subset, 'o-', label=f'NLL ID (K={K_val})', linewidth=2, markersize=6)\n",
        "    axes_metrics_epochs_de[0, 0].plot(epochs_subset, nll_ood_subset, 's-', label=f'NLL OOD (K={K_val})', linewidth=2, markersize=6)\n",
        "    \n",
        "    # Plot CRPS vs epochs\n",
        "    axes_metrics_epochs_de[0, 1].plot(epochs_subset, crps_id_subset, 'o-', label=f'CRPS ID (K={K_val})', linewidth=2, markersize=6)\n",
        "    axes_metrics_epochs_de[0, 1].plot(epochs_subset, crps_ood_subset, 's-', label=f'CRPS OOD (K={K_val})', linewidth=2, markersize=6)\n",
        "    \n",
        "    # Plot Spearman Aleatoric vs epochs\n",
        "    axes_metrics_epochs_de[1, 0].plot(epochs_subset, spear_ale_id_subset, 'o-', label=f'Spear Ale ID (K={K_val})', linewidth=2, markersize=6)\n",
        "    axes_metrics_epochs_de[1, 0].plot(epochs_subset, spear_ale_ood_subset, 's-', label=f'Spear Ale OOD (K={K_val})', linewidth=2, markersize=6)\n",
        "    \n",
        "    # Plot Spearman Epistemic vs epochs\n",
        "    axes_metrics_epochs_de[1, 1].plot(epochs_subset, spear_epi_id_subset, 'o-', label=f'Spear Epi ID (K={K_val})', linewidth=2, markersize=6)\n",
        "    axes_metrics_epochs_de[1, 1].plot(epochs_subset, spear_epi_ood_subset, 's-', label=f'Spear Epi OOD (K={K_val})', linewidth=2, markersize=6)\n",
        "\n",
        "axes_metrics_epochs_de[0, 0].set_xlabel('Epochs', fontsize=12)\n",
        "axes_metrics_epochs_de[0, 0].set_ylabel('NLL', fontsize=12)\n",
        "axes_metrics_epochs_de[0, 0].set_title(f'Deep Ensemble: NLL vs Epochs\\n{function_name} Function ({noise_type.capitalize()})', fontsize=13, fontweight='bold')\n",
        "axes_metrics_epochs_de[0, 0].legend(fontsize=9, ncol=2)\n",
        "axes_metrics_epochs_de[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "axes_metrics_epochs_de[0, 1].set_xlabel('Epochs', fontsize=12)\n",
        "axes_metrics_epochs_de[0, 1].set_ylabel('CRPS', fontsize=12)\n",
        "axes_metrics_epochs_de[0, 1].set_title(f'Deep Ensemble: CRPS vs Epochs\\n{function_name} Function ({noise_type.capitalize()})', fontsize=13, fontweight='bold')\n",
        "axes_metrics_epochs_de[0, 1].legend(fontsize=9, ncol=2)\n",
        "axes_metrics_epochs_de[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "axes_metrics_epochs_de[1, 0].set_xlabel('Epochs', fontsize=12)\n",
        "axes_metrics_epochs_de[1, 0].set_ylabel('Spearman Correlation', fontsize=12)\n",
        "axes_metrics_epochs_de[1, 0].set_title(f'Deep Ensemble: Spearman Aleatoric vs Epochs\\n{function_name} Function ({noise_type.capitalize()})', fontsize=13, fontweight='bold')\n",
        "axes_metrics_epochs_de[1, 0].legend(fontsize=9, ncol=2)\n",
        "axes_metrics_epochs_de[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "axes_metrics_epochs_de[1, 1].set_xlabel('Epochs', fontsize=12)\n",
        "axes_metrics_epochs_de[1, 1].set_ylabel('Spearman Correlation', fontsize=12)\n",
        "axes_metrics_epochs_de[1, 1].set_title(f'Deep Ensemble: Spearman Epistemic vs Epochs\\n{function_name} Function ({noise_type.capitalize()})', fontsize=13, fontweight='bold')\n",
        "axes_metrics_epochs_de[1, 1].legend(fontsize=9, ncol=2)\n",
        "axes_metrics_epochs_de[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.suptitle(f'Deep Ensemble Parameter Comparison: Metrics vs Epochs', \n",
        "             fontsize=14, fontweight='bold', y=0.995)\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save plot\n",
        "save_plot(fig_metrics_epochs_de, f\"Deep_Ensemble_metrics_epochs_comparison_{function_name}_{noise_type}\", \n",
        "          subfolder=f\"comparisons/{noise_type}/{func_type}\")\n",
        "plt.show()\n",
        "plt.close(fig_metrics_epochs_de)\n",
        "\n",
        "# Create summary table (for first epoch value to keep it manageable)\n",
        "# Use already filtered data\n",
        "comparison_df_de = pd.DataFrame({\n",
        "    'K': K_filtered,\n",
        "    'Epochs': [epochs_list_de[i] for i in range(len(epochs_list_de)) if mask_first_epoch_de[i]],\n",
        "    'Avg_Ale_ID': avg_ale_id_filtered_de,\n",
        "    'Avg_Epi_ID': avg_epi_id_filtered_de,\n",
        "    'Avg_Tot_ID': avg_tot_id_filtered_de,\n",
        "    'Avg_Ale_OOD': avg_ale_ood_filtered_de,\n",
        "    'Avg_Epi_OOD': avg_epi_ood_filtered_de,\n",
        "    'Avg_Tot_OOD': avg_tot_ood_filtered_de,\n",
        "    'Avg_Ale_Entropy_ID': avg_ale_entropy_id_filtered_de,\n",
        "    'Avg_Epi_Entropy_ID': avg_epi_entropy_id_filtered_de,\n",
        "    'Avg_Tot_Entropy_ID': avg_tot_entropy_id_filtered_de,\n",
        "    'Avg_Ale_Entropy_OOD': avg_ale_entropy_ood_filtered_de,\n",
        "    'Avg_Epi_Entropy_OOD': avg_epi_entropy_ood_filtered_de,\n",
        "    'Avg_Tot_Entropy_OOD': avg_tot_entropy_ood_filtered_de,\n",
        "    'MSE_ID': mse_id_filtered_de,\n",
        "    'MSE_OOD': mse_ood_filtered_de,\n",
        "    'NLL_ID': nll_id_filtered_de,\n",
        "    'NLL_OOD': nll_ood_filtered_de,\n",
        "    'CRPS_ID': crps_id_filtered_de,\n",
        "    'CRPS_OOD': crps_ood_filtered_de,\n",
        "    'Spear_Ale_ID': spearman_aleatoric_id_filtered_de,\n",
        "    'Spear_Ale_OOD': spearman_aleatoric_ood_filtered_de,\n",
        "    'Spear_Epi_ID': spearman_epistemic_id_filtered_de,\n",
        "    'Spear_Epi_OOD': spearman_epistemic_ood_filtered_de\n",
        "})\n",
        "\n",
        "print(\"\\nSummary Table:\")\n",
        "print(comparison_df_de.to_string(index=False))\n",
        "\n",
        "# Save comparison table\n",
        "save_statistics(comparison_df_de, f\"Deep_Ensemble_K_comparison_{function_name}_{noise_type}\",\n",
        "                subfolder=f\"comparisons/{noise_type}/{func_type}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Overall Comparison Summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a combined summary\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"OVERALL COMPARISON SUMMARY\")\n",
        "print(f\"{'='*80}\\n\")\n",
        "\n",
        "print(\"MC Dropout - Best Parameters (lowest OOD MSE):\")\n",
        "best_mc_idx = np.argmin(mse_ood_list)\n",
        "best_mc_samples = mc_samples_list[best_mc_idx]\n",
        "print(f\"  MC Samples: {best_mc_samples}\")\n",
        "print(f\"  OOD MSE: {mse_ood_list[best_mc_idx]:.6f}\")\n",
        "print(f\"  OOD Epistemic Uncertainty: {avg_epi_ood_list[best_mc_idx]:.6f}\")\n",
        "\n",
        "print(\"\\nDeep Ensemble - Best Parameters (lowest OOD MSE):\")\n",
        "best_de_idx = np.argmin(mse_ood_list_de)\n",
        "best_K = K_list[best_de_idx]\n",
        "print(f\"  K: {best_K}\")\n",
        "print(f\"  OOD MSE: {mse_ood_list_de[best_de_idx]:.6f}\")\n",
        "print(f\"  OOD Epistemic Uncertainty: {avg_epi_ood_list_de[best_de_idx]:.6f}\")\n",
        "\n",
        "# Create side-by-side comparison plot\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# MC Dropout: Epistemic uncertainty comparison\n",
        "axes[0].plot(mc_samples_list, avg_epi_id_list, 'o-', label='Epistemic (ID)', color='blue', linewidth=2, markersize=8)\n",
        "axes[0].plot(mc_samples_list, avg_epi_ood_list, 's-', label='Epistemic (OOD)', color='red', linewidth=2, markersize=8)\n",
        "axes[0].set_xlabel('MC Samples', fontsize=12)\n",
        "axes[0].set_ylabel('Average Epistemic Uncertainty', fontsize=12)\n",
        "axes[0].set_title(f'MC Dropout: Epistemic Uncertainty\\n{function_name} Function ({noise_type.capitalize()})', fontsize=13, fontweight='bold')\n",
        "axes[0].legend(fontsize=10)\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "axes[0].set_xticks(mc_samples_list)\n",
        "\n",
        "# Deep Ensemble: Epistemic uncertainty comparison\n",
        "axes[1].plot(K_list, avg_epi_id_list_de, 'o-', label='Epistemic (ID)', color='blue', linewidth=2, markersize=8)\n",
        "axes[1].plot(K_list, avg_epi_ood_list_de, 's-', label='Epistemic (OOD)', color='red', linewidth=2, markersize=8)\n",
        "axes[1].set_xlabel('Number of Nets (K)', fontsize=12)\n",
        "axes[1].set_ylabel('Average Epistemic Uncertainty', fontsize=12)\n",
        "axes[1].set_title(f'Deep Ensemble: Epistemic Uncertainty\\n{function_name} Function ({noise_type.capitalize()})', fontsize=13, fontweight='bold')\n",
        "axes[1].legend(fontsize=10)\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "axes[1].set_xticks(K_list)\n",
        "\n",
        "plt.suptitle('Parameter Comparison: ID vs OOD Epistemic Uncertainty', \n",
        "             fontsize=14, fontweight='bold', y=1.02)\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save plot\n",
        "save_plot(fig, f\"Overall_comparison_{function_name}_{noise_type}\", \n",
        "          subfolder=f\"comparisons/{noise_type}/{func_type}\")\n",
        "plt.show()\n",
        "plt.close(fig)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
