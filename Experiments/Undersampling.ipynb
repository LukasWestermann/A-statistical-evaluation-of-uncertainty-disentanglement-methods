{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Undersampling Experiments\n",
        "\n",
        "This notebook runs experiments to evaluate uncertainty quantification methods when training data is non-uniformly distributed (spatially undersampled).\n",
        "\n",
        "The experiments train models on data with different sampling densities across regions (e.g., well-sampled in the middle, undersampled on the sides) and evaluate uncertainties across these regions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Packages\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from typing import Tuple\n",
        "import sys\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "import os\n",
        "import pyro\n",
        "\n",
        "# Add parent directory to path to import Models\n",
        "# This works for notebooks in the Experiments folder\n",
        "project_root = Path.cwd().parent if Path.cwd().name == 'Experiments' else Path.cwd()\n",
        "sys.path.insert(0, str(project_root))\n",
        "\n",
        "# Setup results directory\n",
        "results_dir = project_root / \"results\" / \"undersampling\"\n",
        "results_dir.mkdir(parents=True, exist_ok=True)\n",
        "plots_dir = results_dir / \"plots\"\n",
        "plots_dir.mkdir(exist_ok=True)\n",
        "stats_dir = results_dir / \"statistics\"\n",
        "stats_dir.mkdir(exist_ok=True)\n",
        "outputs_dir = results_dir / \"outputs\"\n",
        "outputs_dir.mkdir(exist_ok=True)\n",
        "\n",
        "print(f\"Results will be saved to: {results_dir}\")\n",
        "\n",
        "# Import from Models folder\n",
        "from Models.MC_Dropout import (\n",
        "    MCDropoutRegressor,\n",
        "    train_model,\n",
        "    mc_dropout_predict,\n",
        "    gaussian_nll,\n",
        "    beta_nll,\n",
        "    plot_toy_data,\n",
        "    plot_uncertainties,\n",
        "    normalize_x,\n",
        "    normalize_x_data\n",
        ")\n",
        "\n",
        "from Models.Deep_Ensemble import (\n",
        "    train_ensemble_deep,\n",
        "    ensemble_predict_deep\n",
        ")\n",
        "\n",
        "from Models.BNN import (\n",
        "    train_bnn,\n",
        "    bnn_predict,\n",
        "    normalize_x as bnn_normalize_x,\n",
        "    normalize_x_data as bnn_normalize_x_data\n",
        ")\n",
        "\n",
        "from Models.BAMLSS import (\n",
        "    fit_bamlss,\n",
        "    bamlss_predict\n",
        ")\n",
        "\n",
        "from utils.device import get_device\n",
        "from utils.plotting import plot_uncertainties_undersampling\n",
        "import utils.results_save as results_save_module\n",
        "from utils.results_save import save_plot, save_statistics, save_summary_text, save_summary_statistics\n",
        "from utils.plotting import plot_data_with_ood_regions\n",
        "\n",
        "# Import helper functions for undersampling experiments\n",
        "from utils.undersampling_experiments import (\n",
        "    run_mc_dropout_undersampling_experiment,\n",
        "    run_deep_ensemble_undersampling_experiment,\n",
        "    run_bnn_undersampling_experiment,\n",
        "    run_bamlss_undersampling_experiment\n",
        ")\n",
        "\n",
        "# Set the module-level directories for results_save\n",
        "results_save_module.plots_dir = plots_dir\n",
        "results_save_module.stats_dir = stats_dir\n",
        "results_save_module.outputs_dir = outputs_dir\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Device Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = get_device()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate Toy Datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Reproducibility\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "# ----- Data generation for linear function with homo/heteroscedastic noise -----\n",
        "# f(x) = 0.7x + 0.5\n",
        "# noise_type: 'homoscedastic' (σ(x) = 0.20) or 'heteroscedastic' (σ(x) = 0.10 + 0.2(0.5 + 0.5sin(x)))\n",
        "def generate_toy_regression(n_train=1000, train_range=(-5, 10.0), grid_points=1000, noise_type='heteroscedastic', type = \"linear\"):\n",
        "    \"\"\"\n",
        "    Generate toy regression data.\n",
        "    \n",
        "    Args:\n",
        "        n_train: Number of training samples\n",
        "        train_range: Training range tuple (min, max)\n",
        "        grid_points: Number of grid points for evaluation\n",
        "        noise_type: 'homoscedastic' or 'heteroscedastic'\n",
        "        type: 'linear' or 'sin'\n",
        "    \n",
        "    Returns:\n",
        "        (x_train, y_train, x_grid, y_grid_clean)\n",
        "    \"\"\"\n",
        "    # Sample training data uniformly from train_range\n",
        "    x_train = np.random.uniform(train_range[0], train_range[1], size=(n_train, 1))\n",
        "    \n",
        "    if type == \"linear\":\n",
        "        # Linear function: f(x) = 0.7x + 0.5\n",
        "        f_clean = lambda x: 0.7 * x + 0.5\n",
        "        y_clean_train = f_clean(x_train)\n",
        "    elif type == \"sin\":\n",
        "        f_clean = lambda x:  x * np.sin(x) + x\n",
        "        y_clean_train = f_clean(x_train)\n",
        "    else:\n",
        "        raise ValueError(\"type must be 'linear', 'sin'\")\n",
        "\n",
        "    # Define noise variance σ²(x)\n",
        "    if noise_type == 'homoscedastic':\n",
        "        # Homoscedastic: σ(x) = 2\n",
        "        sigma = 1\n",
        "        sigma_train = np.full_like(x_train, sigma)\n",
        "    elif noise_type == 'heteroscedastic':\n",
        "        # Heteroscedastic: \n",
        "        sigma_train = np.abs(2.5 * np.sin(0.5*x_train +5))\n",
        "    else:\n",
        "        raise ValueError(\"noise_type must be 'homoscedastic' or 'heteroscedastic'\")\n",
        "    \n",
        "    # Generate noise: ε | x ~ N(0, σ²(x))\n",
        "    epsilon = np.random.normal(0.0, sigma_train, size=(n_train, 1))\n",
        "    y_train = y_clean_train + epsilon\n",
        "\n",
        "    # Dense evaluation grid\n",
        "    x_grid = np.linspace(train_range[0], train_range[1], grid_points).reshape(-1, 1)\n",
        "    y_grid_clean = f_clean(x_grid)\n",
        "\n",
        "    return (x_train.astype(np.float32), y_train.astype(np.float32),\n",
        "            x_grid.astype(np.float32), y_grid_clean.astype(np.float32))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Set parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_train = 1000\n",
        "train_range = (-5, 10)\n",
        "# Define sampling regions with different densities\n",
        "# Format: [(region_tuple, density_factor), ...]\n",
        "# density_factor: 0.0-1.0+ representing relative sampling density\n",
        "# Example: [((-5, 0), 0.2), ((0, 5), 1.0), ((5, 10), 0.2)]\n",
        "#   - Regions (-5, 0) and (5, 10) are undersampled (density 0.2)\n",
        "#   - Region (0, 5) is well-sampled (density 1.0)\n",
        "sampling_regions = [((-5, 2), 1), ((2, 6), 0.1), ((6, 10), 1)]\n",
        "grid_points = 1500\n",
        "seed = 42\n",
        "torch.manual_seed(seed)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## MC Dropout\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "### homoscedastic ###\n",
        "\n",
        "run_mc_dropout_undersampling_experiment(\n",
        "    generate_toy_regression_func=generate_toy_regression,\n",
        "    function_types=['linear', 'sin'],\n",
        "    noise_type='homoscedastic',\n",
        "    train_range=train_range,\n",
        "    sampling_regions=sampling_regions,\n",
        "    n_train=n_train,\n",
        "    grid_points=grid_points,\n",
        "    seed=seed,\n",
        "    beta=0.5,\n",
        "    lr=1e-3,\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "### heteroscedastic ####\n",
        "\n",
        "run_mc_dropout_undersampling_experiment(\n",
        "    generate_toy_regression_func=generate_toy_regression,\n",
        "    function_types=['linear', 'sin'],\n",
        "    noise_type='heteroscedastic',\n",
        "    train_range=train_range,\n",
        "    sampling_regions=sampling_regions,\n",
        "    n_train=n_train,\n",
        "    grid_points=grid_points,\n",
        "    seed=seed,\n",
        "    beta=0.5,\n",
        "    lr=1e-3,\n",
        "    batch_size=32\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Deep Ensemble\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### homo ###\n",
        "\n",
        "run_deep_ensemble_undersampling_experiment(\n",
        "    generate_toy_regression_func=generate_toy_regression,\n",
        "    function_types=['linear', 'sin'],\n",
        "    noise_type='homoscedastic',\n",
        "    train_range=train_range,\n",
        "    sampling_regions=sampling_regions,\n",
        "    n_train=n_train,\n",
        "    grid_points=grid_points,\n",
        "    seed=seed,\n",
        "    beta=0.5,\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "### hetero ###\n",
        "\n",
        "run_deep_ensemble_undersampling_experiment(\n",
        "    generate_toy_regression_func=generate_toy_regression,\n",
        "    function_types=['linear', 'sin'],\n",
        "    noise_type='heteroscedastic',\n",
        "    train_range=train_range,\n",
        "    sampling_regions=sampling_regions,\n",
        "    n_train=n_train,\n",
        "    grid_points=grid_points,\n",
        "    seed=seed,\n",
        "    beta=0.5,\n",
        "    batch_size=32\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## BAMLSS - Homoscedastic\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "### homo ###\n",
        "\n",
        "run_bamlss_undersampling_experiment(\n",
        "    generate_toy_regression_func=generate_toy_regression,\n",
        "    function_types=['linear', 'sin'],\n",
        "    noise_type='homoscedastic',\n",
        "    train_range=train_range,\n",
        "    sampling_regions=sampling_regions,\n",
        "    n_train=n_train,\n",
        "    grid_points=grid_points,\n",
        "    seed=seed,\n",
        "    n_iter=12000,\n",
        "    burnin=2000,\n",
        "    thin=10,\n",
        "    nsamples=1000,\n",
        ")\n",
        "\n",
        "### hetero ###\n",
        "\n",
        "run_bamlss_undersampling_experiment(\n",
        "    generate_toy_regression_func=generate_toy_regression,\n",
        "    function_types=['linear', 'sin'],\n",
        "    noise_type='heteroscedastic',\n",
        "    train_range=train_range,\n",
        "    sampling_regions=sampling_regions,\n",
        "    n_train=n_train,\n",
        "    grid_points=grid_points,\n",
        "    seed=seed,\n",
        "    n_iter=12000,\n",
        "    burnin=2000,\n",
        "    thin=10,\n",
        "    nsamples=1000\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## BNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### homo ###\n",
        "\n",
        "run_bnn_undersampling_experiment(\n",
        "    generate_toy_regression_func=generate_toy_regression,\n",
        "    function_types=['linear', 'sin'],\n",
        "    noise_type='homoscedastic',\n",
        "    train_range=train_range,\n",
        "    sampling_regions=sampling_regions,\n",
        "    n_train=n_train,\n",
        "    grid_points=grid_points,\n",
        "    seed=seed,\n",
        "    hidden_width=16,\n",
        "    weight_scale=1.0,\n",
        "    warmup=500,\n",
        "    samples=500,\n",
        "    chains=4\n",
        ")\n",
        "\n",
        "### hetero ###\n",
        "\n",
        "run_bnn_undersampling_experiment(\n",
        "    generate_toy_regression_func=generate_toy_regression,\n",
        "    function_types=['linear', 'sin'],\n",
        "    noise_type='heteroscedastic',\n",
        "    train_range=train_range,\n",
        "    sampling_regions=sampling_regions,\n",
        "    n_train=n_train,\n",
        "    grid_points=grid_points,\n",
        "    seed=seed,\n",
        "    hidden_width=16,\n",
        "    weight_scale=1.0,\n",
        "    warmup=400,\n",
        "    samples=400,\n",
        "    chains=4\n",
        ")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
